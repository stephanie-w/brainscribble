---
title: "R : Variance Inflation"
author: "Stephanie W"
date: "2/8/2015"
output: html_document
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
library(knitr)
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, fig.align = 'center', dpi = 100, tidy = T, cache = F, cache.path = '.cache/', fig.path = 'fig/')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```

A variance inflation factor (VIF) is a ratio of estimated variances, the variance due to including the ith regressor, divided by that due to including a corresponding ideal regressor which is uncorrelated with the others.
VIF is the square of standard error inflation.

```{r}
mdl <- lm(Fertility ~ ., data=swiss)
library(car)
vif(mdl)
```

For each regression coefficient, the variance inflation due to including all the others.  
For instance, the variance in the estimated coefficient of Education is 2.774943 times what it might have been if Education were not correlated with the other regressors. 
We can guess that Examination and Education are likely to be correlated, so most of the variance inflation for Education is due to including Examination.

```{r}
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
```

As expected, omitting Examination in the model decreased the VIF for Education, from 2.774943 to 1.816361. Notice it has almost no effect on the VIF for Infant Mortality.

Including new variables to a model will increase standard errors of coefficient estimates of other correlated refressors. On the other hand, omitting varaibles results can bias in coefficients of regressors which are correlated with the omitted one.

Analysis of variance (ANOVA) is a useful way to quantify the significance of additional regressors.

```{r}
fit1 <- lm(Fertility ~ Agriculture, data=swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, data=swiss)
anova(fit1, fit3)
```

The null hypothesis is rejected at the 0.001 level based on a right-tailed F test (F value=20.968).  

RSS (Residual sum of squares) are 6283.1 and 3180.9  
We can check the results with the R's deviance function, which calculate the residual sum of squares:

```{r}
deviance(fit1)
deviance(fit3)
```

The F statistic is the ratio of the two sums of squares divided by their respective degrees of freedom.
For the F value computing, this is the ratio of the difference of deviance divided by the difference in the residual degrees of freedom of fit1 and fit3 (2) and the fit3's residual sum of squares divided by its degrees of freedom. fit3 has 43 residual degrees of freedom (47 number of samples - 4 predictors (the 3 named and the intercept)):
```{r}
n <- (deviance(fit1) - deviance(fit3))/2
d <- deviance(fit3)/43
n/d

```
If the two scaled sums are independent and centrally chi-squared distributed with the same variance, the statistic will have an F distribution with parameters given by the two degrees of freedom.

For the p-value is the probability that a value of n/d or larger would be drawn from an F distribution which has parameters 2 and 43. The p-value is 4.407e-07, a very unlikely value if the null hypothesis vwere true.

The p-value can be computed with the R's pf function:
```{r}
pf(n/d, 2, 43, lower.tail=FALSE)

```

Based on the calculated p-value, a false rejection of the null hypothesis is extremely unlikely. We are confident that fit3 is significantly better than fit1, with one caveat: analysis of variance is sensitive to its assumption that model residuals are approximately normal.
If they are not, we could get a small p-value for that reason.

t is thus worth testing residuals for normality. The Shapiro-Wilk test tests the residual of fit 3. Normality is its null hypothesis.

```{r}
shapiro.test(fit3$residuals)

```

The Shapiro-Wilk p-value of 0.336 fails to reject normality, supporting confidence in the analysis of variance.


We can go on with ANOVA and other variables:

```{r}
fit5 <- lm(Fertility ~ Agriculture + Examination + Education + Catholic, data=swiss)
fit6 <- lm(Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality, data=swiss)
anova(fit1, fit3, fit5, fit6)

```
It appears that each model is a significant improvement on its predecessor
