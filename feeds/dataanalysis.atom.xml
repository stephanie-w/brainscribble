<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Brain Scribble</title><link href="http://stephanie-w.github.io/blog/" rel="alternate"></link><link href="http://stephanie-w.github.io/blog/feeds/dataanalysis.atom.xml" rel="self"></link><id>http://stephanie-w.github.io/blog/</id><updated>2015-08-16T01:02:29+02:00</updated><entry><title>R : Exploring Data for Machine Learning Modeling</title><link href="http://stephanie-w.github.io/blog/exploring-data-for-marchine-learning.html" rel="alternate"></link><updated>2015-08-16T01:02:29+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-16:blog/exploring-data-for-marchine-learning.html</id><summary type="html">
&lt;hr/&gt;

&lt;p&gt;These are my notes on the Practical Machine Learning course (Week2: Plotting Predictors - Tutorial).&lt;/p&gt;

&lt;p&gt;When exploring data for Machine Learning, we're looking for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;imbalance outcomes/predictors&lt;/li&gt;
&lt;li&gt;outliners&lt;/li&gt;
&lt;li&gt;groups of outcome points not explained by any of the predictors&lt;/li&gt;
&lt;li&gt;skewed variables (that needs to be transformed)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We'll use the Wage dataset from the ISLR package.&lt;br/&gt;
This dataset reports wage and other data (age, education, jobclass, etc.) for a group of 3000 male workers in the Mid-Atlantic region.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ISLR&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;(&lt;/span&gt;Wage&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;Wage&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##       year           age               sex                    maritl           race     &lt;/span&gt;
&lt;span class="code-line"&gt;##  Min.   :2003   Min.   :18.00   1. Male  :3000   1. Never Married: 648   1. White:2480  &lt;/span&gt;
&lt;span class="code-line"&gt;##  1st Qu.:2004   1st Qu.:33.75   2. Female:   0   2. Married      :2074   2. Black: 293  &lt;/span&gt;
&lt;span class="code-line"&gt;##  Median :2006   Median :42.00                    3. Widowed      :  19   3. Asian: 190  &lt;/span&gt;
&lt;span class="code-line"&gt;##  Mean   :2006   Mean   :42.41                    4. Divorced     : 204   4. Other:  37  &lt;/span&gt;
&lt;span class="code-line"&gt;##  3rd Qu.:2008   3rd Qu.:51.00                    5. Separated    :  55                  &lt;/span&gt;
&lt;span class="code-line"&gt;##  Max.   :2009   Max.   :80.00                                                           &lt;/span&gt;
&lt;span class="code-line"&gt;##                                                                                         &lt;/span&gt;
&lt;span class="code-line"&gt;##               education                     region               jobclass               health    &lt;/span&gt;
&lt;span class="code-line"&gt;##  1. &amp;lt; HS Grad      :268   2. Middle Atlantic   :3000   1. Industrial :1544   1. &amp;lt;=Good     : 858  &lt;/span&gt;
&lt;span class="code-line"&gt;##  2. HS Grad        :971   1. New England       :   0   2. Information:1456   2. &amp;gt;=Very Good:2142  &lt;/span&gt;
&lt;span class="code-line"&gt;##  3. Some College   :650   3. East North Central:   0                                              &lt;/span&gt;
&lt;span class="code-line"&gt;##  4. College Grad   :685   4. West North Central:   0                                              &lt;/span&gt;
&lt;span class="code-line"&gt;##  5. Advanced Degree:426   5. South Atlantic    :   0                                              &lt;/span&gt;
&lt;span class="code-line"&gt;##                           6. East South Central:   0                                              &lt;/span&gt;
&lt;span class="code-line"&gt;##                           (Other)              :   0                                              &lt;/span&gt;
&lt;span class="code-line"&gt;##   health_ins      logwage           wage       &lt;/span&gt;
&lt;span class="code-line"&gt;##  1. Yes:2083   Min.   :3.000   Min.   : 20.09  &lt;/span&gt;
&lt;span class="code-line"&gt;##  2. No : 917   1st Qu.:4.447   1st Qu.: 85.38  &lt;/span&gt;
&lt;span class="code-line"&gt;##                Median :4.653   Median :104.92  &lt;/span&gt;
&lt;span class="code-line"&gt;##                Mean   :4.654   Mean   :111.70  &lt;/span&gt;
&lt;span class="code-line"&gt;##                3rd Qu.:4.857   3rd Qu.:128.68  &lt;/span&gt;
&lt;span class="code-line"&gt;##                Max.   :5.763   Max.   :318.34  &lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Building training and testing sets (50% of the dataset each):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;caret&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;intrain &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; createDataPartition&lt;span class="p"&gt;(&lt;/span&gt;y &lt;span class="o"&gt;=&lt;/span&gt; Wage&lt;span class="o"&gt;$&lt;/span&gt;wage&lt;span class="p"&gt;,&lt;/span&gt; p &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;training &lt;span class="o"&gt;=&lt;/span&gt; Wage&lt;span class="p"&gt;[&lt;/span&gt;intrain&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;testing &lt;span class="o"&gt;=&lt;/span&gt; Wage&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;intrain&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The exploration is always done on the training set.&lt;/p&gt;
&lt;h2 id="plotting-predictors-against-outcome"&gt;Plotting predictors against outcome&lt;/h2&gt;
&lt;p&gt;Plotting wage versus age, education and jobclass using the R featurePlot function (from the caret package):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;featurePlot&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; training&lt;span class="p"&gt;[,&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"age"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"education"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"jobclass"&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; training&lt;span class="o"&gt;$&lt;/span&gt;wage&lt;span class="p"&gt;,&lt;/span&gt; plot &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"pairs"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img src="figure/exploring-data-for-marchine-learning-3-1.png"/&gt;&lt;/div&gt;
&lt;p&gt;The graph shows some patterns: a trend in wages comparing to ages and two distinct groups of observations (below and above 250 dollars raw wage).&lt;/p&gt;
&lt;p&gt;Plotting wage versus age:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;qplot&lt;span class="p"&gt;(&lt;/span&gt;age&lt;span class="p"&gt;,&lt;/span&gt; wage&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; training&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img src="figure/exploring-data-for-marchine-learning-4-2.png"/&gt;&lt;/div&gt;
&lt;p&gt;Plotting wage versus age, grouping by jobclass:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img src="figure/exploring-data-for-marchine-learning-4-1.png"/&gt;&lt;/div&gt;
&lt;p&gt;The jobclass difference could explain the two distincts groups.&lt;/p&gt;
&lt;p&gt;Plotting wage versus age, grouping by education, adding regression smoothers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;qq &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; qplot&lt;span class="p"&gt;(&lt;/span&gt;age&lt;span class="p"&gt;,&lt;/span&gt; wage&lt;span class="p"&gt;,&lt;/span&gt; color &lt;span class="o"&gt;=&lt;/span&gt; education&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; training&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;qq &lt;span class="o"&gt;+&lt;/span&gt; geom_smooth&lt;span class="p"&gt;(&lt;/span&gt;method &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"lm"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; formula &lt;span class="o"&gt;=&lt;/span&gt; y &lt;span class="o"&gt;~&lt;/span&gt; x&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img src="figure/exploring-data-for-marchine-learning-5-1.png"/&gt;&lt;/div&gt;
&lt;h2 id="data-repartition"&gt;Data Repartition&lt;/h2&gt;
&lt;p&gt;Breaking up the wage variable into three groups (factors actually) with the R cut2 function (from the Hmisc package):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;Hmisc&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;cutWage &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; cut2&lt;span class="p"&gt;(&lt;/span&gt;training&lt;span class="o"&gt;$&lt;/span&gt;wage&lt;span class="p"&gt;,&lt;/span&gt; g &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cutWage&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## cutWage&lt;/span&gt;
&lt;span class="code-line"&gt;## [ 20.1, 91.7) [ 91.7,118.9) [118.9,314.3] &lt;/span&gt;
&lt;span class="code-line"&gt;##           506           519           476&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Looling at the repartition, we can see that there are more industrial jobs that there are information jobs with lower wage. Then the trend reverses itself.&lt;/p&gt;
&lt;p&gt;Plotting a boxplot of the wage groups created above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;qplot&lt;span class="p"&gt;(&lt;/span&gt;cutWage&lt;span class="p"&gt;,&lt;/span&gt; age&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; training&lt;span class="p"&gt;,&lt;/span&gt; fill &lt;span class="o"&gt;=&lt;/span&gt; cutWage&lt;span class="p"&gt;,&lt;/span&gt; geom &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"boxplot"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img src="figure/exploring-data-for-marchine-learning-7-1.png"/&gt;&lt;/div&gt;
&lt;p&gt;Exploring the repartition of jobclass across wage groups:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;t1 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cutWage&lt;span class="p"&gt;,&lt;/span&gt; training&lt;span class="o"&gt;$&lt;/span&gt;jobclass&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;t1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##                &lt;/span&gt;
&lt;span class="code-line"&gt;## cutWage         1. Industrial 2. Information&lt;/span&gt;
&lt;span class="code-line"&gt;##   [ 20.1, 91.7)           313            193&lt;/span&gt;
&lt;span class="code-line"&gt;##   [ 91.7,118.9)           262            257&lt;/span&gt;
&lt;span class="code-line"&gt;##   [118.9,314.3]           190            286&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using the prop function to get the proportion of jobclass (in each row) for each groups:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kp"&gt;prop.table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;t1&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##                &lt;/span&gt;
&lt;span class="code-line"&gt;## cutWage         1. Industrial 2. Information&lt;/span&gt;
&lt;span class="code-line"&gt;##   [ 20.1, 91.7)     0.6185771      0.3814229&lt;/span&gt;
&lt;span class="code-line"&gt;##   [ 91.7,118.9)     0.5048170      0.4951830&lt;/span&gt;
&lt;span class="code-line"&gt;##   [118.9,314.3]     0.3991597      0.6008403&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;62% of the low wage job correponds to industrial jobs, 38% to information jobs.&lt;/p&gt;
&lt;h2 id="density-plots"&gt;Density Plots&lt;/h2&gt;
&lt;p&gt;Density plot can be a much more effective way to view the distribution of a variable than boxplots.&lt;/p&gt;
&lt;p&gt;Ploting a density plot of the values of wages, grouping by education:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;qplot&lt;span class="p"&gt;(&lt;/span&gt;wage&lt;span class="p"&gt;,&lt;/span&gt; color &lt;span class="o"&gt;=&lt;/span&gt; education&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; training&lt;span class="p"&gt;,&lt;/span&gt; geom &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"density"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img src="figure/exploring-data-for-marchine-learning-10-1.png"/&gt;&lt;/div&gt;
&lt;p&gt;The "&amp;lt;HS grad" workers tend to have more values in the lower part of the range of wage. There is an outgroup of Advanced Degree and College Grad workers with higher wage.&lt;/p&gt;</summary><category term="R"></category></entry><entry><title>Confusion Matrix</title><link href="http://stephanie-w.github.io/blog/confusion-matrix.html" rel="alternate"></link><updated>2015-08-16T01:02:15+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-16:blog/confusion-matrix.html</id><summary type="html">&lt;hr /&gt;


&lt;p&gt;A confusion matrix, also known as a contingency table or an error matrix or tavle of confusion, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix).&lt;/p&gt;


&lt;p&gt;It is a table with two rows and two columns that reports the number of false positives, false negatives, true positives, and true negatives.&lt;/p&gt;
&lt;p&gt;For example, for a test that screens people for a given disease, the confusion matrix will be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;                         Disease&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;                 +         |        -&lt;/span&gt;
&lt;span class="code-line"&gt;         ------------------|------------------&lt;/span&gt;
&lt;span class="code-line"&gt;Test  +  x true positives  |  z false positives&lt;/span&gt;
&lt;span class="code-line"&gt;      -  y false negatives |  t true negatives&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;with
x true positives (TP) : the number of sick people correctly identified as sick
z false positives (FP) : the number of healthy people incorrectly identified as sick
t true negatives (TN) : the number of healthy people correctly identified as healthy
y false negatives (FN) : the number of sick people incorrectly identified as healthy&lt;/p&gt;
&lt;p&gt;The following probabilities are associated with the confusion matrix:&lt;br /&gt;
Sensitivity -&amp;gt; &lt;span class="math"&gt;\(Pr\left(positive test | disease\right)\)&lt;/span&gt;&lt;br /&gt;
Specificity -&amp;gt; &lt;span class="math"&gt;\(Pr\left(negative test | no disease\right)\)&lt;/span&gt;&lt;br /&gt;
Positive Predictive Value -&amp;gt; &lt;span class="math"&gt;\(Pr\left(disease| positive test\right)\)&lt;/span&gt;&lt;br /&gt;
Negative Predictive Value -&amp;gt; &lt;span class="math"&gt;\(Pr\left(no disease| negative test\right)\)&lt;/span&gt;&lt;br /&gt;
Accuracy -&amp;gt; &lt;span class="math"&gt;\(Pr\left(correct outcome\right)\)&lt;/span&gt; ie. Sensitivity + Specificity  &lt;/p&gt;
&lt;p&gt;Sensitivity -&amp;gt; &lt;span class="math"&gt;\(\frac{TP}{TP+FN}\)&lt;/span&gt;&lt;br /&gt;
Specificity -&amp;gt; &lt;span class="math"&gt;\(\frac{TN}{FP+TN}\)&lt;/span&gt;&lt;br /&gt;
Positive Predictive Value -&amp;gt; &lt;span class="math"&gt;\(\frac{TP}{TP+FP}\)&lt;/span&gt;&lt;br /&gt;
Negative Predictive Value -&amp;gt; &lt;span class="math"&gt;\(\frac{TN}{FN+TN}\)&lt;/span&gt;&lt;br /&gt;
Accuracy -&amp;gt; &lt;span class="math"&gt;\(\frac{TP+TN}{TP+FP+FN+TN}\)&lt;/span&gt;  &lt;/p&gt;
&lt;h2 id="examples"&gt;Examples&lt;/h2&gt;
&lt;p&gt;A diagnostic test with sensitivity 67% and specificity 91% is applied to 2030 people to look for a disorder with a population prevalence of 1.48%.&lt;/p&gt;
&lt;p&gt;Let's build the associated 2Ã—2 contingency table:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="figure/confusion-matrix-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="figure/confusion-matrix-2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Suppose that we have created a machine learning algorithm that predicts whether a link will be clicked with 99% sensitivity and 99% specificity. The rate the link is clicked is 1/1000 of visits to a website. If we predict the link will be clicked on a specific visit, what is the probability it will actually be clicked?&lt;/p&gt;
&lt;p&gt;Let's be 100000 the number of visits:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="figure/confusion-matrix-3.png" /&gt;&lt;/p&gt;
&lt;p&gt;According to the confusion matrix above, the probability that the link will be actually clicked is 9%.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary></entry><entry><title>R: Multivariable Regression</title><link href="http://stephanie-w.github.io/blog/multivariable-regression.html" rel="alternate"></link><updated>2015-08-16T01:01:47+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-16:blog/multivariable-regression.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;

This is my note on swirl course Regression Model : Multivariable Examples 3. &lt;/p&gt;
&lt;p&gt;We'll use the hunger dataset from the course:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;download.file&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://raw.githubusercontent.com/swirldev/swirl_courses/master/Regression_Models/MultiVar_Examples3/hunger.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="s"&gt;&amp;quot;hunger.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; method &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;curl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; quiet &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;hunger &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hunger.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##    X                              Indicator Data.Source PUBLISH.STATES Year WHO.region  Country&lt;/span&gt;
&lt;span class="code-line"&gt;## 1  8 Children aged &amp;lt;5 years underweight (%) NLIS_310044      Published 1986     Africa  Senegal&lt;/span&gt;
&lt;span class="code-line"&gt;## 2 11 Children aged &amp;lt;5 years underweight (%) NLIS_310095      Published 1989     Africa   Uganda&lt;/span&gt;
&lt;span class="code-line"&gt;## 3 13 Children aged &amp;lt;5 years underweight (%) NLIS_310138      Published 1988     Africa Zimbabwe&lt;/span&gt;
&lt;span class="code-line"&gt;## 4 16 Children aged &amp;lt;5 years underweight (%) NLIS_310044      Published 1986     Africa  Senegal&lt;/span&gt;
&lt;span class="code-line"&gt;## 5 18 Children aged &amp;lt;5 years underweight (%) NLIS_310095      Published 1989     Africa   Uganda&lt;/span&gt;
&lt;span class="code-line"&gt;## 6 21 Children aged &amp;lt;5 years underweight (%) NLIS_310138      Published 1988     Africa Zimbabwe&lt;/span&gt;
&lt;span class="code-line"&gt;##      Sex Display.Value Numeric Low High Comments&lt;/span&gt;
&lt;span class="code-line"&gt;## 1   Male          19.3    19.3  NA   NA       NA&lt;/span&gt;
&lt;span class="code-line"&gt;## 2 Female          19.1    19.1  NA   NA       NA&lt;/span&gt;
&lt;span class="code-line"&gt;## 3 Female           7.2     7.2  NA   NA       NA&lt;/span&gt;
&lt;span class="code-line"&gt;## 4 Female          15.3    15.3  NA   NA       NA&lt;/span&gt;
&lt;span class="code-line"&gt;## 5   Male          20.4    20.4  NA   NA       NA&lt;/span&gt;
&lt;span class="code-line"&gt;## 6   Male           8.7     8.7  NA   NA       NA&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Numeric column gives the percentage of children under age 5 who were underweight when that sample was taken.&lt;br /&gt;
We fit a simple linear regression for Numeric (outcome) on Year:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;fit &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Numeric &lt;span class="o"&gt;~&lt;/span&gt; Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;fit&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Call:&lt;/span&gt;
&lt;span class="code-line"&gt;## lm(formula = Numeric ~ Year, data = hunger)&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Residuals:&lt;/span&gt;
&lt;span class="code-line"&gt;##     Min      1Q  Median      3Q     Max &lt;/span&gt;
&lt;span class="code-line"&gt;## -24.621 -11.196  -1.994   7.085  45.039 &lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Coefficients:&lt;/span&gt;
&lt;span class="code-line"&gt;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &lt;/span&gt;
&lt;span class="code-line"&gt;## (Intercept) 634.47966  121.14460   5.237 2.01e-07 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## Year         -0.30840    0.06053  -5.095 4.21e-07 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## ---&lt;/span&gt;
&lt;span class="code-line"&gt;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Residual standard error: 13.23 on 946 degrees of freedom&lt;/span&gt;
&lt;span class="code-line"&gt;## Multiple R-squared:  0.02671,    Adjusted R-squared:  0.02568 &lt;/span&gt;
&lt;span class="code-line"&gt;## F-statistic: 25.96 on 1 and 946 DF,  p-value: 4.209e-07&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As time goes on, the rate of hunger decreases.&lt;br /&gt;
The intercept of the model represents the percentage of hungry children at year 0.  &lt;/p&gt;
&lt;p&gt;Let's look at the rates of hunger for the different genders to see how, or even if, they differ:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;lmF &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Numeric&lt;span class="p"&gt;[&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Female&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; Year&lt;span class="p"&gt;[&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Female&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; hunger&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmF&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Call:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; lm(formula = Numeric[hunger$Sex == &amp;quot;Female&amp;quot;] ~ Year[hunger$Sex == &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;     &amp;quot;Female&amp;quot;], data = hunger)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Residuals:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;     Min      1Q  Median      3Q     Max &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; -23.228 -10.638  -1.959   6.859  46.146 &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Coefficients:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;                               Estimate Std. Error t value Pr(&amp;gt;|t|)    &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; (Intercept)                  603.50580  167.53201   3.602 0.000349 ***&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Year[hunger$Sex == &amp;quot;Female&amp;quot;]  -0.29340    0.08371  -3.505 0.000500 ***&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; ---&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Residual standard error: 12.94 on 472 degrees of freedom&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Multiple R-squared:  0.02537,    Adjusted R-squared:  0.0233 &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; F-statistic: 12.29 on 1 and 472 DF,  p-value: 5e-04&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;lmM &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Numeric&lt;span class="p"&gt;[&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Male&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; Year&lt;span class="p"&gt;[&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Male&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; hunger&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmM&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Call:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; lm(formula = Numeric[hunger$Sex == &amp;quot;Male&amp;quot;] ~ Year[hunger$Sex == &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;     &amp;quot;Male&amp;quot;], data = hunger)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Residuals:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;     Min      1Q  Median      3Q     Max &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; -25.913 -11.741  -1.832   7.399  42.255 &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Coefficients:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;                             Estimate Std. Error t value Pr(&amp;gt;|t|)    &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; (Intercept)                665.45352  174.50726   3.813 0.000155 ***&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Year[hunger$Sex == &amp;quot;Male&amp;quot;]  -0.32340    0.08719  -3.709 0.000233 ***&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; ---&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Residual standard error: 13.48 on 472 degrees of freedom&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; Multiple R-squared:  0.02832,    Adjusted R-squared:  0.02626 &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; F-statistic: 13.76 on 1 and 472 DF,  p-value: 0.0002328&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We plot the data points and fitted lines using different colors to distinguish between males (blue) and females (pink).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;plot&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="o"&gt;$&lt;/span&gt;Numeric&lt;span class="p"&gt;,&lt;/span&gt; type &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;points&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="o"&gt;$&lt;/span&gt;Numeric&lt;span class="p"&gt;,&lt;/span&gt; pch &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Female&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;125&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;lines&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;[&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Male&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; lmM&lt;span class="o"&gt;$&lt;/span&gt;fitted&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;lines&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;[&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Female&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; lmF&lt;span class="o"&gt;$&lt;/span&gt;fitted&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;red&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/multivariable-regression-4-1.png"/&gt;&lt;/div&gt;

&lt;p&gt;We can see from the plot that the lines are not exactly parallel. On the right side of the graph (around the year 2010) they are closer together than on the left side (around 1970). Slopes are -0.29340 for femals, -0.32340 for males.&lt;/p&gt;
&lt;p&gt;Now instead of separating the data by subsetting the samples by gender, we'll use gender as another predictor to create the linear model:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;lmBoth &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Numeric &lt;span class="o"&gt;~&lt;/span&gt; Year &lt;span class="o"&gt;+&lt;/span&gt; Sex&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; hunger&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmBoth&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Call:&lt;/span&gt;
&lt;span class="code-line"&gt;## lm(formula = Numeric ~ Year + Sex, data = hunger)&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Residuals:&lt;/span&gt;
&lt;span class="code-line"&gt;##     Min      1Q  Median      3Q     Max &lt;/span&gt;
&lt;span class="code-line"&gt;## -25.472 -11.297  -1.848   7.058  45.990 &lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Coefficients:&lt;/span&gt;
&lt;span class="code-line"&gt;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &lt;/span&gt;
&lt;span class="code-line"&gt;## (Intercept) 633.5283   120.8950   5.240 1.98e-07 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## Year         -0.3084     0.0604  -5.106 3.99e-07 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## SexMale       1.9027     0.8576   2.219   0.0267 *  &lt;/span&gt;
&lt;span class="code-line"&gt;## ---&lt;/span&gt;
&lt;span class="code-line"&gt;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Residual standard error: 13.2 on 945 degrees of freedom&lt;/span&gt;
&lt;span class="code-line"&gt;## Multiple R-squared:  0.03175,    Adjusted R-squared:  0.0297 &lt;/span&gt;
&lt;span class="code-line"&gt;## F-statistic: 15.49 on 2 and 945 DF,  p-value: 2.392e-07&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice that Male and Female are factors (factors are treated in alphabetic order, so reference, here, is the Female group).&lt;br /&gt;
The intercept represents the percentage of hungry females at year 0.&lt;br /&gt;
The estimate for the factor Male 1.9027 is a distance from the intercept (the estimate of the reference group Female). So the percentage of hungry males at year 0 is the sum of the intercept and the male estimate, ie. 633.5283 + 1.9027 = 635.431&lt;br /&gt;
The estimate for hunger$Year represents the annual decrease in percentage of both gender.&lt;/p&gt;
&lt;p&gt;In the plot, the red line will have the female intercept and the  blue line will have the male intercept:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;plot&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="o"&gt;$&lt;/span&gt;Numeric&lt;span class="p"&gt;,&lt;/span&gt; pch &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;points&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="o"&gt;$&lt;/span&gt;Numeric&lt;span class="p"&gt;,&lt;/span&gt; pch &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Female&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;125&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;abline&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmBoth&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; lmBoth&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;red&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;abline&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmBoth&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; lmBoth&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; lmBoth&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/multivariable-regression-6-1.png"/&gt;&lt;/div&gt;

&lt;p&gt;The lines are parallels (since, they have the same slope lmBoth$coeff[2]).&lt;/p&gt;
&lt;p&gt;Now we'll consider the interaction between year and gender to see how that affects changes in rates of hunger:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;lmInter &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Numeric &lt;span class="o"&gt;~&lt;/span&gt; Year &lt;span class="o"&gt;+&lt;/span&gt; Sex &lt;span class="o"&gt;+&lt;/span&gt; Sex &lt;span class="o"&gt;*&lt;/span&gt; Year&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; hunger&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmInter&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Call:&lt;/span&gt;
&lt;span class="code-line"&gt;## lm(formula = Numeric ~ Year + Sex + Sex * Year, data = hunger)&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Residuals:&lt;/span&gt;
&lt;span class="code-line"&gt;##     Min      1Q  Median      3Q     Max &lt;/span&gt;
&lt;span class="code-line"&gt;## -25.913 -11.248  -1.853   7.087  46.146 &lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Coefficients:&lt;/span&gt;
&lt;span class="code-line"&gt;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &lt;/span&gt;
&lt;span class="code-line"&gt;## (Intercept)  603.50580  171.05519   3.528 0.000439 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## Year          -0.29340    0.08547  -3.433 0.000623 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## SexMale       61.94772  241.90858   0.256 0.797946    &lt;/span&gt;
&lt;span class="code-line"&gt;## Year:SexMale  -0.03000    0.12087  -0.248 0.804022    &lt;/span&gt;
&lt;span class="code-line"&gt;## ---&lt;/span&gt;
&lt;span class="code-line"&gt;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Residual standard error: 13.21 on 944 degrees of freedom&lt;/span&gt;
&lt;span class="code-line"&gt;## Multiple R-squared:  0.03181,    Adjusted R-squared:  0.02874 &lt;/span&gt;
&lt;span class="code-line"&gt;## F-statistic: 10.34 on 3 and 944 DF,  p-value: 1.064e-06&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The percentage of hungry females at year 0 is 603.5058.&lt;br /&gt;
The percentage of hungry males at year 0 is 665.4535 (603.50580  + 61.94772).&lt;br /&gt;
The annual change (decrease) in percentage of hungry females is 0.29340.&lt;br /&gt;
The estimate associated with Year:SexMale represents the distance of the annual change in percent of males from that of females.
The annual change in percentage of hungry males is -0.32340 (-0.29340 - 0.03000).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;plot&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="o"&gt;$&lt;/span&gt;Numeric&lt;span class="p"&gt;,&lt;/span&gt; pch &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;points&lt;span class="p"&gt;(&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Year&lt;span class="p"&gt;,&lt;/span&gt; hunger&lt;span class="o"&gt;$&lt;/span&gt;Numeric&lt;span class="p"&gt;,&lt;/span&gt; pch &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;hunger&lt;span class="o"&gt;$&lt;/span&gt;Sex &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Male&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;125&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;abline&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmInter&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; lmInter&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;red&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;abline&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;lmInter&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; lmInter&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; lmInter&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; lmInter&lt;span class="o"&gt;$&lt;/span&gt;coeff&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/multivariable-regression-8-1.png"/&gt;&lt;/div&gt;

&lt;p&gt;The lines are not parallel and will eventually intersect. The Male blue line indicates a faster rate of change.&lt;/p&gt;
&lt;p&gt;Here we're dealing with an interaction between factors.&lt;/p&gt;
&lt;p&gt;Suppose we have two interacting predictors and one of them is held constant.&lt;br /&gt;
The expected change in the outcome for a unit change in the other predictor is the coefficient of that changing predictor  + the coefficient of the interaction * the value of the predictor held constant.&lt;/p&gt;
&lt;p&gt;For example, let's the model be : &lt;span class="math"&gt;\(H_i = b_0 + (b_1*I_i) + (b_2*Y_i)+ (b_3*I_i*Y_i)\)&lt;/span&gt; with H the outcomes, I's and Y's the predictors and b's the estimated coefficients of the predictors.&lt;br /&gt;
If I is fixed at a value, 5 and Y varies, &lt;span class="math"&gt;\(b_2 + b3*5\)&lt;/span&gt; represents the change in H per unit change in Y given that I is fixed at 5.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="R"></category></entry><entry><title>Notes on Statistical Inference : Hypothesis Testing and t-tests</title><link href="http://stephanie-w.github.io/blog/statinf2.html" rel="alternate"></link><updated>2015-08-10T16:19:08+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-10:blog/statinf2.html</id><summary type="html">
&lt;hr/&gt;
&lt;p&gt;
These are  my notes on the Statistical Inference course (2th part) : Hypothesis Testing and t-tests&lt;/p&gt;

&lt;h2 id="clt-central-limit-theorem"&gt;CLT : Central Limit Theorem&lt;/h2&gt;
&lt;p&gt;The distribution of sample statistics (e.g. mean) is approximatively normal, regardless of the underlying distribution, with mean = &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and variance = &lt;span class="math"&gt;\(\sigma^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\bar{X} \sim N(mean = \mu, sd = \frac{\sigma}{\sqrt{n}})\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;Conditions for CLT:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Independence : The sampled observations must be independent &lt;ul&gt;
&lt;li&gt;random sample / assignment&lt;/li&gt;
&lt;li&gt;if sampling without replacement, n &amp;lt; 10 % of population&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sample Size / skew :&lt;ul&gt;
&lt;li&gt;population should be normal&lt;/li&gt;
&lt;li&gt;if not sample size should be large (rule of thumb &amp;gt; 30)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="confidence-interval"&gt;Confidence Interval&lt;/h2&gt;
&lt;p&gt;A confidence interval gives an estimated range of values which is likely to include an unknown population parameter, the estimated range being calculated from a given set of sample data (the interval is a random observed variable depending on the sample).  &lt;/p&gt;
&lt;p&gt;The level &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; of a confidence interval gives the probability that the interval produced by the method employed includes the true value of this parameter.
The level of confidence is the percentage of chance the unknown parameter is contained in the interval (which would differ for each sample across repeated sampling).
The confidence interval represents values for the population parameter for which the difference between this parameter and the observed estimate is not statistically significant at the &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; level.  &lt;/p&gt;
&lt;p&gt;Let X be a random sample from a probability distribution &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, a quantity to be estimated. A confidence interval I for &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; with confidence level &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; has the property:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P(\theta \in I(x)) \geq 1 - \alpha\)&lt;/span&gt; with P a density probability depending on theta.&lt;/p&gt;
&lt;p&gt;Let's take the example of the estimation of the mean of a population normally distributed which is the simpleast usage of condidence interval.&lt;br/&gt;
The confidence interval of a sample mean &lt;span class="math"&gt;\(\bar X\)&lt;/span&gt; from a normally distributed sample is also normally distributed (from CLT), with the same expectation &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and a standard deviation :&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac {\sigma}{\sqrt{n}}\)&lt;/span&gt; (the standard deviation of a dsitribution of sample means is called standard error, SE)&lt;/p&gt;
&lt;p&gt;By standardizing &lt;span class="math"&gt;\(\bar X\)&lt;/span&gt;, we get a random variable: &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(Z = \frac {\bar X-\mu}{\sigma/\sqrt{n}}\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;Z depend on the parameter &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; to be estimated and a standard normal distribution independent of the parameter &lt;span class="math"&gt;\(\mu\)&lt;/span&gt;. We look for numbers -z and z, independent of &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; between which Z lies with a probability &lt;span class="math"&gt;\(1 - \alpha\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;For a 95% of confidence, we take &lt;span class="math"&gt;\(1 - \alpha\)&lt;/span&gt; = 0.95, so&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\!P(-z\le Z\le z) = 1-\alpha = 0.95\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Z follows the cumulative normal distribution (Z is standardized)&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\Phi(z) = P(Z \le z) = 1 - \tfrac{\alpha}{2} = 0.975\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\Phi(z)  = \Phi^{-1}(\Phi(z)) = \Phi^{-1}(0.975) = 1.96\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://upload.wikimedia.org/wikipedia/en/b/bf/NormalDist1.96.png"/&gt;
1.96 correspond to the 95% + 2.5% = 97.5% quantile of the normal distribution, according to the Z table (find 0.975 in the table and add the column header with the row header).
&lt;img alt="" src="http://cosstatistics.pbworks.com/f/1281154582/6368.png"/&gt;
&lt;img alt="Standard deviation diagram" src="https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg"/&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(0.95 = 1-\alpha=P(-z \le Z \le z)=P \left(-1.96 \le \frac {\bar X-\mu}{\sigma/\sqrt{n}} \le 1.96 \right)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(0.95 = P \left( \bar X - 1.96 \frac{\sigma}{\sqrt{n}} \le \mu \le \bar X + 1.96 \frac{\sigma}{\sqrt{n}}\right)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The lower endpoint of the the interval is &lt;span class="math"&gt;\(\bar X - 1.96 \frac{\sigma}{\sqrt{n}}\)&lt;/span&gt; &lt;br/&gt;
The upper endpoint of the the interval is &lt;span class="math"&gt;\(\bar X + 1.96 \frac{\sigma}{\sqrt{n}}\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;We've computed our interval that can be interpreted this way : If we take 100 samples of  size n and for each sample we compute the interval, then the parameter will be in 95 of the intervals computed, and outside of 5 intervals. We are 95% confident ot the result. &lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;p&gt;You have taken a random sample of 100 primary school children. Their heights had mean = 150cm and sd = 10 cm. We estimate the true average height of primary school children based on this sample using a 95% confidence interval.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\bar{x} = z \times SE = x\bar \pm 1.96 \times \frac{s}{\sqrt{n}} = 150 \pm 1.96 \times \frac{10}{\sqrt{100}} = 150 \pm \times 1.96 \times 1 = (148.04, 151.96)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are 95% confident that primary school children mean height is between 148.04cm and 151.96cm.&lt;/p&gt;
&lt;p&gt;As the standard deviation of the population &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; is known in this case, the distribution of the sample mean &lt;span class="math"&gt;\(\bar X\)&lt;/span&gt; is a normal distribution with &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; the only unknown parameter. In most of practical case, the parameter &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; is also unknown, which calls for using the (Student's) t-distribution.&lt;/p&gt;
&lt;h2 id="required-sample-size-for-margin-of-error"&gt;Required sample size for margin of error&lt;/h2&gt;
&lt;p&gt;Given a target margin of error and confidence level, and the standard deviation of a sample (or population), we can work backwards to determine the required sample size.&lt;/p&gt;
&lt;p&gt;Example :&lt;/p&gt;
&lt;p&gt;From previous measurements of primary school heights. What should be the sample size in order to get a 95% confidence interval with a margin of error less or equal to 1 cm:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(ME = z \times SE\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(1 = 1.96 \times \frac{10}{\sqrt{n}}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(n = \left(\frac{1.96 \times 10}{1}\right)^2 = 19.6^2 = 384.16\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus we need a sample size of at least 385 primary school children.&lt;/p&gt;
&lt;h2 id="hypothesis-testing"&gt;Hypothesis testing&lt;/h2&gt;
&lt;p&gt;When interpreting an experimental finding, a natural question arises as to whether the finding could have occurred by chance. Hypothesis testing is a statistical procedure for testing whether chance is a plausible explanation of an experimental finding.&lt;/p&gt;
&lt;p&gt;The researcher has a proposed hypothesis about a population characteristic and conducts a study to discover if it is reasonable, or, acceptable.&lt;/p&gt;
&lt;p&gt;Null Hypothesis &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; : The status quo that is assumed to be true. &lt;br/&gt;
Alternative hypothesis &lt;span class="math"&gt;\(H_a\)&lt;/span&gt; : An alternative claim under consideration that will require statistical evidence to accept, and thus, reject the null hypothesis. The alternative hypothesis claims that the population characteristic is different than the observed parameter. This difference is either that the characteristic has increased, decreased, or, possibly either increased or decreased.&lt;/p&gt;
&lt;p&gt;The alternative hypotheses are typically of the form &amp;lt; (decrease), &amp;gt; (increase) or &lt;span class="math"&gt;\(\neq\)&lt;/span&gt; (either increase or decrease).
We have four possible outcomes:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Truth&lt;/th&gt;
&lt;th&gt;Decide&lt;/th&gt;
&lt;th&gt;Result&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;H0&lt;/td&gt;
&lt;td&gt;H0&lt;/td&gt;
&lt;td&gt;Correctly accept null&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;H0&lt;/td&gt;
&lt;td&gt;Ha&lt;/td&gt;
&lt;td&gt;Type I error (False Positive, falsely claims a significant result)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ha&lt;/td&gt;
&lt;td&gt;Ha&lt;/td&gt;
&lt;td&gt;Correctly reject null&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ha&lt;/td&gt;
&lt;td&gt;H0&lt;/td&gt;
&lt;td&gt;Type II error (False Negative falsely claims a nonsignificant result)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A test statistic is used to make an assumption, the null is made upon this assumption. The test statistic will have a certain likelihood for occurring, according to the distribution being used. When this likelihood is small, this indicates that the sample data are either from an unusual sample, or, that the distribution of the population actually is different than assumed. 
If the sample is properly drawn, there is small risk that the sample is unusual, and, so, it is safe to draw a conclusion that the distribution may be changed.  This allows the conclusion that the null hypothesis may have changed, and that the alternative hypothesis might be accepted instead.  This conclusion leads the researcher to "reject" the null hypothesis.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;p&gt;From previous example, does the data support the hypothesis that primary school children on average are shorter than 151cm?&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(H_0 : \mu_0 = 151\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(H_a : \mu_0 &amp;lt; 151\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Assuming &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, how unusual or extreme is the sample value we get from our OBSERVED data? or
Assuming &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, what is the probability to obtain the observed data (ie. a mean of 150cm &amp;lt; 151 cm, with a sd=10cm) or a more extreme values?&lt;/p&gt;
&lt;p&gt;An equivalent question is, assuming &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, ie. assuming X' normally distributed with &lt;span class="math"&gt;\(X' \sim N(150, 1)\)&lt;/span&gt;, what is the probability to obtain a standard deviation at least that far from the mean? &lt;/p&gt;
&lt;p&gt;We must determine how our hypothesis mean is far from our OBSERVED sample mean (the z-score):&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(Z = \frac{\bar{X} - \mu}{\bar{\sigma_X}} = \frac{150 - 151}{1} = -1\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our observed data are -1 standard deviation from the hypothesis mean.&lt;/p&gt;
&lt;p&gt;A reasonable strategy would be : do not reject the null hypothesis, ie. "primary school children have mean height of 151 cm", if there is more than x% chance of getting a random sample of 100 children with a sample mean 150, with x enough hight (more than 5% usually).&lt;/p&gt;
&lt;p&gt;The probability under the null hypothesis of obtaining evidence as or more extreme than your z-score or test statistic (obtained from your observed data) in the direction of the alternative hypothesis is the p-value.&lt;/p&gt;
&lt;h2 id="p-value"&gt;P-value&lt;/h2&gt;
&lt;p&gt;Probability of obtaining the observed result or results that are more "extreme", given that hypothesis is true, ie. P(observed or more extreme outcome | &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;A reasonable strategy would reject the null hypothesis if the sample mean &lt;span class="math"&gt;\(\bar X\)&lt;/span&gt; is larger or lower than some constant C, chosen so that the probability of a Type I error is &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note:
  &lt;span class="math"&gt;\(C = \mu + qnorm(\alpha) \times sd\)&lt;/span&gt;
  instead of computing a constant C as a cutpoint for accepting or rejecting &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, we simply compute a Z-score based on alpha, the number of standard deviations the sample mean is from the hypothesized mean.&lt;/p&gt;
&lt;p&gt;If the p-value is low (ie. lower than the significant level (&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;), usually 5% as a standard level of rejection), then we saw that is very unlikely to observe the data if the null hypothesis is true and reject it.&lt;/p&gt;
&lt;p&gt;If the p-value is high (ie. higher than (&lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;), we say that it is likely to observe the data even if the null hypothesis was true, and thus do not reject it.&lt;/p&gt;
&lt;h2 id="interpreting-the-p-value"&gt;Interpreting the p-value&lt;/h2&gt;
&lt;p&gt;When a probability value is below the &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; level, the effect is statistically significant and the null hypothesis is rejected.&lt;br/&gt;
However, not all statistically significant effects should be treated the same way. For example, you should have less confidence that the null hypothesis is false if p = 0.049 than p = 0.003.&lt;br/&gt;
If the null hypothesis is rejected, then the alternative to the null hypothesis (called the alternative hypothesis) is accepted.  &lt;/p&gt;
&lt;p&gt;In many situations it is very unlikely two conditions will have the same population means. Therefore, even before an experiment comparing their effectiveness is conducted, the researcher knows that the null hypothesis of exactly no difference is false. If a test of the difference is significant, then the direction of the difference is established.&lt;/p&gt;
&lt;p&gt;When a significance test results in a high probability value, it means that the data provide little or no evidence that the null hypothesis is false. However, the high probability value is not evidence that the null hypothesis is true. The problem is that it is impossible to distinguish a null effect from a very small effect.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;p&gt;From the previous example, with a significant level equal to 0.05:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\bar{X} \sim N(\mu = 151, SE = 1)\)&lt;/span&gt; #Null hypothesis&lt;/p&gt;
&lt;p&gt;Test statistic or Z-score:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(Z = \frac{\bar X - \mu}{SE} = \frac{150 - 151}{1} = -1\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The probability that we are at most -1 standard deviation from the mean:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P\left(Z &amp;lt; -1\right) = 1 - 0.8413 = 0.1587\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This probability can be computed with the qnorm R function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;pnorm&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 0.1586553&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we assume &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; (&lt;span class="math"&gt;\(mu = 151\)&lt;/span&gt;), the probability of getting a sample this "extreme" (&lt;span class="math"&gt;\(\mu = 150\)&lt;/span&gt;) or actually more extreme is 15.9%.
Since p-value is higher than 5%, we don't to reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Interpretation :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If in fact, primary school children have mean height of 151 cm, there is a 15,9% chance that a random sample of 100 children would yield a sample mean of 150cm or lower.&lt;/li&gt;
&lt;li&gt;This is a pretty hight probability&lt;/li&gt;
&lt;li&gt;Thus the sample mean of 150 could have likely occured by chance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="two-sided-hypothesis-testing"&gt;Two-sided Hypothesis testing&lt;/h2&gt;
&lt;p&gt;The test above was a one-side or one-tailed test.
What is the probability that the children have mean height different from 151cm?&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(H_0 : \mu = 151\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(H_a : \mu \neq 151\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We could reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; (and accept &lt;span class="math"&gt;\(H_a\)&lt;/span&gt;) when our sample mean is significant different that 151, that is either less than OR greater that 151. 
We consider values at both tails at the .025 and the .975 percentiles.
This means that the test statistic is less than .025, Z_(alpha/2), or greater than .975, Z_(1-alpha/2).
Notice that if we reject H_0, either it was FALSE (and hence our model is wrong and we are correct to reject it) OR H_0 is TRUE and we have made an error (Type I). The probability of this is 5%.&lt;/p&gt;
&lt;p&gt;P-value:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P\left(Z &amp;lt; -1\right) +  P\left(Z &amp;gt; 1\right) = 2 \times (1-0.8413) = 0.3174\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With R:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; pnorm&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 0.3173105&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="decision-rule"&gt;Decision rule&lt;/h2&gt;
&lt;p&gt;The decision rule is to reject the null hypothesis H0 if the observed value is in the critical region, and to accept or "fail to reject" the hypothesis otherwise.&lt;/p&gt;
&lt;p&gt;Left Tailed Test: &lt;br/&gt;
&lt;span class="math"&gt;\(H_0 : \mu = \mu_0\)&lt;/span&gt; parameter = value &lt;br/&gt;
&lt;span class="math"&gt;\(H_a : \mu &amp;lt; \mu_0\)&lt;/span&gt; parameter  &amp;lt; value &lt;br/&gt;
with alpha = 0.5 &lt;br/&gt;
Reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, if the test statistics is in the region of rejection, ie. if it is smaller than Z_5.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;Z_95 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; qnorm&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.95&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;Z_95&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 1.644854&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the 95% percentile corresponds to the value 1.64 (see also zthe z table above).&lt;/p&gt;
&lt;div class="rimage center"&gt;&lt;img alt="plot of chunk Z_5" class="plot" src="figure/Z_5-1.png" title="plot of chunk Z_5"/&gt;&lt;/div&gt;
&lt;p&gt;Right Tailed Test: &lt;br/&gt;
&lt;span class="math"&gt;\(H_0 : \mu = \mu_0\)&lt;/span&gt; parameter = value &lt;br/&gt;
&lt;span class="math"&gt;\(H_a : \mu &amp;gt; \mu_0\)&lt;/span&gt; parameter &amp;gt; value &lt;br/&gt;
Reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, if the test statistics is in the region of rejection, ie. if it is larger than Z_95.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;Z_5 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; qnorm&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;Z_5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] -1.644854&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="rimage center"&gt;&lt;img alt="plot of chunk Z_95" class="plot" src="figure/Z_95-1.png" title="plot of chunk Z_95"/&gt;&lt;/div&gt;
&lt;p&gt;Two Tailed Test: &lt;br/&gt;
&lt;span class="math"&gt;\(H_0 : \mu = \mu_0\)&lt;/span&gt; parameter = value &lt;br/&gt;
&lt;span class="math"&gt;\(H_a : \mu \neq \mu_0\)&lt;/span&gt; parameter &lt;span class="math"&gt;\(\neq\)&lt;/span&gt; value  (Another way to write not equal is &amp;lt; or &amp;gt;) &lt;br/&gt;
Reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, if the test statistics is in the region of rejection, ie. if it is larger than Z_95 or smaller than Z_5.   &lt;/p&gt;
&lt;p&gt;The decision rule can be summarized as follows:&lt;/p&gt;
&lt;p&gt;Reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; if the test statistic falls in the critical region (reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; if the test statistic is more extreme than the critical value or reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; ), otherwise, we fail to reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The p-value tells us if the test statistic is inside our outside the region. &lt;br/&gt;
Reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; if p-value is less that the specified &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;, otherwise, we fail to reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note : I you fail to reject the one sided test, you know that you will fail to reject the two sided.&lt;/p&gt;
&lt;h2 id="hypothesis-tests-and-confidence-intervals"&gt;Hypothesis tests and Confidence Intervals&lt;/h2&gt;
&lt;p&gt;They're equivalent.&lt;br/&gt;
If you set &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; to some value and ran many tests checking alternative hypotheses against &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; that &lt;span class="math"&gt;\(\mu=\mu_0\)&lt;/span&gt;, the set of all possible values for which you fail to reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; forms the &lt;span class="math"&gt;\((1\alpha)%\)&lt;/span&gt; (that is 95%) confidence interval for &lt;span class="math"&gt;\(\mu_0\)&lt;/span&gt;.
Similarly, if a &lt;span class="math"&gt;\((1\alpha)%\)&lt;/span&gt; interval contains mu_0, then we fail to reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So, to resume:
If the confidence interval contains the null value (&lt;span class="math"&gt;\(\mu_0\)&lt;/span&gt;, the value of &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;), don't reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;.
If the confidence interval does not contain the null value, reject &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, cause this tells us that either our hypothesis is wrong or we're making a mistake (Type 1) in rejecting it.&lt;/p&gt;
&lt;p&gt;Previously, we found the 95% interval for heights of primary school children to be (148, 152). Given that our null hypothesis (&lt;span class="math"&gt;\(H_0 = 151\)&lt;/span&gt;) falls within this 95% Cl, we do not reject it.&lt;/p&gt;
&lt;pre&gt;&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;              &amp;lt;- 95% confident that the av is somewherer in here -&amp;gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    ---------|-----------------------------------------------------|---------&lt;/span&gt;
&lt;span class="code-line"&gt;             148cm                                                 152&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;A two-sided hypothesis with significance level &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; is equivalent to a confidence interval with &lt;span class="math"&gt;\(CL = 1 - \alpha\)&lt;/span&gt;. 
A one-sided hypothesis with significance level &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; is equivalent to a confidence interval with &lt;span class="math"&gt;\(CL = 1 - 2\alpha\)&lt;/span&gt;. &lt;/p&gt;
&lt;h2 id="type-ii-error"&gt;Type II error&lt;/h2&gt;
&lt;p&gt;Let the probability of a type II error (accepting H_0 when it is false) to be beta.
The term POWER refers to the quantity 1-beta and it represents the probability of rejecting &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; when it's false. This is used to determine appropriate sample sizes in experiments.&lt;/p&gt;
&lt;h2 id="the-t-distribution"&gt;The t distribution&lt;/h2&gt;
&lt;p&gt;So far, we use normal distribution and implicitly relying on the Central Limit Theorem.
According to CLT, the distribution of sample statistics is approximatively normal, if:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Population is normal&lt;/li&gt;
&lt;li&gt;Sample size is large (n&amp;gt; 30)
If so, we can use the population sd (&lt;span class="math"&gt;\(s\sigma\)&lt;/span&gt;) to compute a z-score.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, when we deal with small sample size and do not know the standard deviation of the population (&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;), we rely on the t distribution.&lt;br/&gt;
The t distribution takes into account that spread of possible &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;'s.&lt;br/&gt;
The test statistic is the same as before &lt;span class="math"&gt;\(\frac{Observed-Expected}{SE}\)&lt;/span&gt; ie. &lt;span class="math"&gt;\(\frac{Observed-Expected}{s/\sqrt{n}}\)&lt;/span&gt; and the test statistic is compared to &lt;span class="math"&gt;\(t_{1-\alpha, df}\)&lt;/span&gt; or/and &lt;span class="math"&gt;\(t_{\alpha, df}\)&lt;/span&gt; (with df the degree of freedom = size - 1).&lt;/p&gt;
&lt;p&gt;Shape of the distribution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Observations are more likely to fall beyond 2 sd from the mean&lt;/li&gt;
&lt;li&gt;The thicker tails are helpful in adjusting for the less reliable data on the standard deviation.
The t distribution has one parameter, degrees of freedom (df) which determines the thickness of the tail&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Under &lt;span class="math"&gt;\(H_0\)&lt;/span&gt;, the probability that the test statistic is larger than the 95th percentile of the t distribution is 5%. The associated quantile is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;n &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;16&lt;/span&gt;  &lt;span class="c1"&gt;# sample size&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;pt&lt;span class="p"&gt;(&lt;/span&gt;q &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; df &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lower.tail &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 0.0122529&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the P(X &amp;gt; 2.5) if &lt;span class="math"&gt;\(H_0\)&lt;/span&gt; were true. We would see this large a test statistic with probability 1% which is rather a small probability.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;df refers to the number of independent observations in data set&lt;/li&gt;
&lt;li&gt;nb of independent observations = sample size - 1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When df increases, the t distribution approaches the normal distribution.&lt;/p&gt;
&lt;p&gt;Normal distribution vs t distribution: if you're unsure which one to use, use the t distribution since it approximates to the normal distribution with large sample sizes.&lt;/p&gt;
&lt;p&gt;T table
&lt;img alt="" src="http://3.bp.blogspot.com/_5u1UHojRiJk/TEdJJc6of2I/AAAAAAAAAIE/Ai0MW5VgIhg/s1600/t-table.jpg"/&gt;&lt;/p&gt;
&lt;h2 id="independent-and-dependent-t-tests"&gt;Independent and dependent t-tests&lt;/h2&gt;
&lt;p&gt;Dependent t-test: when evaluating the effect between two related samples, ie.  when the same subjects are being compared or when two samples are matched at the level of individual subjects.&lt;br/&gt;
Example : You feed a group of 100 people fast food everyday, did they gain weight?&lt;br/&gt;
You can calculate a difference score and then determine if the mean difference score is significantly different from zero and so if there is significantly change.&lt;/p&gt;
&lt;p&gt;Independent t-test: when evaluating the effect between two independent sample: You feed 50 males and 50 males fast food everyday. Did males or females gain more weight after 30 days?&lt;/p&gt;
&lt;h2 id="test-comparisons"&gt;Test Comparisons&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;Observed&lt;/th&gt;
&lt;th&gt;Expected&lt;/th&gt;
&lt;th&gt;SE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;z&lt;/td&gt;
&lt;td&gt;Sample mean&lt;/td&gt;
&lt;td&gt;Pop. mean&lt;/td&gt;
&lt;td&gt;SE of the mean&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t (single sample)&lt;/td&gt;
&lt;td&gt;Sample mean&lt;/td&gt;
&lt;td&gt;Pop. mean&lt;/td&gt;
&lt;td&gt;SE of the mean&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t(dependent)&lt;/td&gt;
&lt;td&gt;Sample mean of &lt;br&gt; difference scores&lt;/br&gt;&lt;/td&gt;
&lt;td&gt;Pop. mean of &lt;br&gt; difference scores&lt;/br&gt;&lt;/td&gt;
&lt;td&gt;SE of the mean difference&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t(independent)&lt;/td&gt;
&lt;td&gt;Difference between &lt;br&gt; two sample means&lt;/br&gt;&lt;/td&gt;
&lt;td&gt;Difference between &lt;br&gt; two pop. mean&lt;/br&gt;&lt;/td&gt;
&lt;td&gt;SE of the difference between means&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--
Test Statistics (in each case, the test statistics = (Observed - Expected) / SE)

-               | value            | SE
----------------|------------------|------------------------
z               |  M - M0 / SE     | S / &amp;radic;N
t(single sample)|                  |  
t(dependent)    |  M - 0 / SE      | 
t(independent)  | (M1 - M2)/SE     | (SE1 + SE2)/2 
--&gt;
&lt;p&gt;Degrees of freedom:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;df&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;z&lt;/td&gt;
&lt;td&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t (single sample)&lt;/td&gt;
&lt;td&gt;N-1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t(dependent)&lt;/td&gt;
&lt;td&gt;N-1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t(independent)&lt;/td&gt;
&lt;td&gt;(N1-1) + (N2-1)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="using-the-r-ttest-function"&gt;Using the R t.test function&lt;/h2&gt;
&lt;h3 id="mean-of-difference"&gt;Mean of difference&lt;/h3&gt;
&lt;p&gt;From the father.son library, which contains 1078 measurements of a father's height and his son's height, we test the mean of the difference of the vectors sheight (son height) and fheight (father height), the null hypothesis is the true mean of the difference is 0.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"UsingR"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;(&lt;/span&gt;father.son&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;t.test&lt;span class="p"&gt;(&lt;/span&gt;father.son&lt;span class="o"&gt;$&lt;/span&gt;sheight &lt;span class="o"&gt;-&lt;/span&gt; father.son&lt;span class="o"&gt;$&lt;/span&gt;fheight&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;  One Sample t-test&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; data:  father.son$sheight - father.son$fheight&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; t = 11.789, df = 1077, p-value &amp;lt; 2.2e-16&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; alternative hypothesis: true mean is not equal to 0&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; 95 percent confidence interval:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;  0.8310296 1.1629160&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; sample estimates:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; mean of x &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; 0.9969728&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As said before, t = &lt;span class="math"&gt;\(\frac{X'-\mu}{SE}\)&lt;/span&gt; ie. &lt;span class="math"&gt;\(\frac{X'- \mu}{s/\sqrt{n}}\)&lt;/span&gt;&lt;br/&gt;
&lt;span class="math"&gt;\(\mu = 0\)&lt;/span&gt; as we test difference of means.
We can check that t = 11.789 as returned by the t.test function,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;v &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; father.son&lt;span class="o"&gt;$&lt;/span&gt;sheight &lt;span class="o"&gt;-&lt;/span&gt; father.son&lt;span class="o"&gt;$&lt;/span&gt;fheight&lt;/span&gt;
&lt;span class="code-line"&gt;t &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;v&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;sd&lt;span class="p"&gt;(&lt;/span&gt;v&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kp"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;v&lt;span class="p"&gt;)))&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;t&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;[1] 11.78855&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;confidence intervals:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;v&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;sd&lt;span class="p"&gt;(&lt;/span&gt;v&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kp"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;v&lt;span class="p"&gt;)))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="difference-in-means"&gt;Difference in means&lt;/h3&gt;
&lt;p&gt;We test the difference in means of the vectors sheight and fheight, the null hypothesis is the true difference in means is 0.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;t.test&lt;span class="p"&gt;(&lt;/span&gt;father.son&lt;span class="o"&gt;$&lt;/span&gt;sheight&lt;span class="p"&gt;,&lt;/span&gt; father.son&lt;span class="o"&gt;$&lt;/span&gt;fheight&lt;span class="p"&gt;,&lt;/span&gt; paired &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;  Paired t-test&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; data:  father.son$sheight and father.son$fheight&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; t = 11.789, df = 1077, p-value &amp;lt; 2.2e-16&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; alternative hypothesis: true difference in means is not equal to 0&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; 95 percent confidence interval:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;  0.8310296 1.1629160&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; sample estimates:&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; mean of the differences &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;               0.9969728&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The test statistic is 11.789 which is quite hight so we reject the null hypothesis that the true mean of the difference is 0, (if you ran the test on the difference sheight-fheight) or that the true difference in means was 0 (if you ran the test on the two separate but paired columns).&lt;/p&gt;
&lt;p&gt;Note the 95% confidence interval, 0.8310296 1.1629160, returned by t.test. It does not contain the hypothesized population mean 0 so we're pretty confident we can safely reject the hypothesis. This tells us that either our hypothesis is wrong or we're making a mistake (Type 1) in rejecting it.&lt;/p&gt;
&lt;!--

Drawing conclusions comparing the probability value ( the probability of obtaining a sample statistic as different or more different from the parameter specified in the null hypothesis given that the null hypothesis is true.) with the $\alpha$ level. If the probability value is lower then you reject the null hypothesis. Keep in mind that rejecting the null hypothesis is not an all-or-none decision. The lower the probability value, the more confidence you can have that the null hypothesis is false. However, if your probability value is higher than the conventional $\alpha$ level of 0.05, most scientists will consider your findings inconclusive. Failure to reject the null hypothesis does not constitute support for the null hypothesis. It just means you do not have sufficiently strong data to reject it. 

There is a close relationship between confidence intervals and significance tests. Specifically, if a statistic is significantly different from 0 at the 0.05 level, then the 95% confidence interval will not contain 0. All values in the confidence interval are plausible values for the parameter, whereas values outside the interval are rejected as plausible values for the parameter


Confidence intervals are closely related to statistical significance testing.
Hypothesis testing is concerned with making decisions using data. It compares the data being studied to an observed characteristic of the population from which the data are sampled.

The 5% is considered as the region of rejection, if the z score is outside the region of rejection (determined by $alpha$), we fail to reject $H_0$.

The p-value is the probability under the null hypothesis of obtaining evidence as or more extreme than your z-score or test statistic (obtained from your observed data) in the direction of the alternative hypothesis.
So if the p-value (probability of seeing your test statistic) is small, then one of two things happens. EITHER $H_0$ is true and you have observed a rare event (in this unusual test statistic) OR $H_0$ is false.

The p-value is as an attained significance level, ie. the smallest value of alpha at which you will reject the null hypothesis.

--&gt;
&lt;!--
Sources 
http://statstutorstl.blogspot.fr/search/label/inferential%20statistics
http://fr.slideshare.net/eugeneyan/statistical-inference-3
http://www.stat.yale.edu/Courses/1997-98/101/confint.htm
--&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="R"></category><category term="stats"></category></entry><entry><title>R : Variance Inflation</title><link href="http://stephanie-w.github.io/blog/variance-inflation.html" rel="alternate"></link><updated>2015-08-10T16:19:08+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-10:blog/variance-inflation.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;This is my note on swirl course Regression Model : Overfitting and Underfitting.&lt;/p&gt;
&lt;h2 id="definition"&gt;Definition&lt;/h2&gt;
&lt;p&gt;
A variance inflation factor (VIF) is a ratio of estimated variances, the variance due to including the ith regressor, divided by that due to including a corresponding ideal regressor which is uncorrelated with the others.
VIF is the square of standard error inflation.&lt;/p&gt;


&lt;p&gt;More simply, it estimates how much the variance of a coefficient is "inflated" because of linear dependence with other predictors. Thus, a VIF of 1.8 tells us that the variance of a particular coefficient is 80% larger than it would be if that predictor was completely uncorrelated with all the other predictors.&lt;br /&gt;
The VIF has a lower bound of 1 but no upper bound. &lt;/p&gt;
&lt;h2 id="examples-with-the-swiss-dataset"&gt;Examples with the swiss dataset&lt;/h2&gt;
&lt;p&gt;To explore VIF, we'll use the Swiss Fertility and Socioeconomic Indicators (1888) dataset which reports standardized fertility measure and socio-economic indicators for each of 47 French-speaking provinces of Switzerland at about 1888. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;data&lt;span class="p"&gt;(&lt;/span&gt;swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We fit a model with Fertility as outcome and use the R's function vif (from the car package) to compute variance inflations:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;data&lt;span class="p"&gt;(&lt;/span&gt;swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;mdl &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Fertility &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="m"&gt;.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;car&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;vif&lt;span class="p"&gt;(&lt;/span&gt;mdl&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##      Agriculture      Examination        Education         Catholic Infant.Mortality &lt;/span&gt;
&lt;span class="code-line"&gt;##         2.284129         3.675420         2.774943         1.937160         1.107542&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For each regression coefficient, the variance inflation due to including all the others.&lt;br /&gt;
For instance, the variance in the estimated coefficient of Education is 2.774943 times what it might have been if Education were not correlated with the other regressors.&lt;br /&gt;
We can guess that Examination and Education are likely to be correlated, so most of the variance inflation for Education is due to including Examination.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;mdl2 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Fertility &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="m"&gt;.&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; Examination&lt;span class="p"&gt;,&lt;/span&gt; swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;vif&lt;span class="p"&gt;(&lt;/span&gt;mdl2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##      Agriculture        Education         Catholic Infant.Mortality &lt;/span&gt;
&lt;span class="code-line"&gt;##         2.147153         1.816361         1.299916         1.107528&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As expected, omitting Examination in the model decreased the VIF for Education, from 2.774943 to 1.816361. Notice it has almost no effect on the VIF for Infant Mortality.&lt;/p&gt;
&lt;p&gt;Including new variables to a model will increase standard errors of coefficient estimates of other correlated refressors. On the other hand, omitting varaibles results can bias in coefficients of regressors which are correlated with the omitted one.&lt;/p&gt;
&lt;p&gt;Analysis of variance (ANOVA) is a useful way to quantify the significance of additional regressors.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;fit1 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Fertility &lt;span class="o"&gt;~&lt;/span&gt; Agriculture&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;fit3 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Fertility &lt;span class="o"&gt;~&lt;/span&gt; Agriculture &lt;span class="o"&gt;+&lt;/span&gt; Examination &lt;span class="o"&gt;+&lt;/span&gt; Education&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;anova&lt;span class="p"&gt;(&lt;/span&gt;fit1&lt;span class="p"&gt;,&lt;/span&gt; fit3&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## Analysis of Variance Table&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Model 1: Fertility ~ Agriculture&lt;/span&gt;
&lt;span class="code-line"&gt;## Model 2: Fertility ~ Agriculture + Examination + Education&lt;/span&gt;
&lt;span class="code-line"&gt;##   Res.Df    RSS Df Sum of Sq      F    Pr(&amp;gt;F)    &lt;/span&gt;
&lt;span class="code-line"&gt;## 1     45 6283.1                                  &lt;/span&gt;
&lt;span class="code-line"&gt;## 2     43 3180.9  2    3102.2 20.968 4.407e-07 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## ---&lt;/span&gt;
&lt;span class="code-line"&gt;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The null hypothesis is rejected at the 0.001 level based on a right-tailed F test (F value=20.968).  &lt;/p&gt;
&lt;p&gt;RSS (Residual sum of squares) are 6283.1 and 3180.9.&lt;br /&gt;
We can check the results with the R's deviance function, which calculate the residual sum of squares:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;deviance&lt;span class="p"&gt;(&lt;/span&gt;fit1&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 6283.116&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;deviance&lt;span class="p"&gt;(&lt;/span&gt;fit3&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 3180.925&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The F statistic is the ratio of the two sums of squares divided by their respective degrees of freedom.&lt;br /&gt;
For the F value computing, this is the ratio of the difference of deviance divided by the difference in the residual degrees of freedom of fit1 and fit3 (2) and the fit3's residual sum of squares divided by its degrees of freedom. fit3 has 43 residual degrees of freedom (47 number of samples - 4 predictors (the 3 named and the intercept)):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;n &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;deviance&lt;span class="p"&gt;(&lt;/span&gt;fit1&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; deviance&lt;span class="p"&gt;(&lt;/span&gt;fit3&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;d &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; deviance&lt;span class="p"&gt;(&lt;/span&gt;fit3&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;43&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;n&lt;span class="o"&gt;/&lt;/span&gt;d&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 20.96783&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If the two scaled sums are independent and centrally chi-squared distributed with the same variance, the statistic will have an F distribution with parameters given by the two degrees of freedom.&lt;/p&gt;
&lt;p&gt;For the p-value is the probability that a value of n/d or larger would be drawn from an F distribution which has parameters 2 and 43. The p-value is 4.407e-07, a very unlikely value if the null hypothesis vwere true.&lt;/p&gt;
&lt;p&gt;The p-value can be computed with the R's pf function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;pf&lt;span class="p"&gt;(&lt;/span&gt;n&lt;span class="o"&gt;/&lt;/span&gt;d&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;43&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lower.tail &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 4.406913e-07&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Based on the calculated p-value, a false rejection of the null hypothesis is extremely unlikely. We are confident that fit3 is significantly better than fit1, with one caveat: analysis of variance is sensitive to its assumption that model residuals are approximately normal.&lt;br /&gt;
If they are not, we could get a small p-value for that reason.&lt;br /&gt;
It is thus worth testing residuals for normality. The Shapiro-Wilk test tests the residual of fit 3. Normality is its null hypothesis.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;shapiro.test&lt;span class="p"&gt;(&lt;/span&gt;fit3&lt;span class="o"&gt;$&lt;/span&gt;residuals&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt;  Shapiro-Wilk normality test&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; &lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; data:  fit3$residuals&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="cp"&gt;##&lt;/span&gt;&lt;span class="c"&gt; W = 0.97276, p-value = 0.336&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Shapiro-Wilk p-value of 0.336 fails to reject normality, supporting confidence in the analysis of variance.&lt;/p&gt;
&lt;p&gt;We can go on with ANOVA and other variables:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;fit5 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Fertility &lt;span class="o"&gt;~&lt;/span&gt; Agriculture &lt;span class="o"&gt;+&lt;/span&gt; Examination &lt;span class="o"&gt;+&lt;/span&gt; Education &lt;span class="o"&gt;+&lt;/span&gt; Catholic&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;fit6 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;Fertility &lt;span class="o"&gt;~&lt;/span&gt; Agriculture &lt;span class="o"&gt;+&lt;/span&gt; Examination &lt;span class="o"&gt;+&lt;/span&gt; Education &lt;span class="o"&gt;+&lt;/span&gt; Catholic &lt;span class="o"&gt;+&lt;/span&gt; Infant.Mortality&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; swiss&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;anova&lt;span class="p"&gt;(&lt;/span&gt;fit1&lt;span class="p"&gt;,&lt;/span&gt; fit3&lt;span class="p"&gt;,&lt;/span&gt; fit5&lt;span class="p"&gt;,&lt;/span&gt; fit6&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## Analysis of Variance Table&lt;/span&gt;
&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;## Model 1: Fertility ~ Agriculture&lt;/span&gt;
&lt;span class="code-line"&gt;## Model 2: Fertility ~ Agriculture + Examination + Education&lt;/span&gt;
&lt;span class="code-line"&gt;## Model 3: Fertility ~ Agriculture + Examination + Education + Catholic&lt;/span&gt;
&lt;span class="code-line"&gt;## Model 4: Fertility ~ Agriculture + Examination + Education + Catholic + &lt;/span&gt;
&lt;span class="code-line"&gt;##     Infant.Mortality&lt;/span&gt;
&lt;span class="code-line"&gt;##   Res.Df    RSS Df Sum of Sq       F    Pr(&amp;gt;F)    &lt;/span&gt;
&lt;span class="code-line"&gt;## 1     45 6283.1                                   &lt;/span&gt;
&lt;span class="code-line"&gt;## 2     43 3180.9  2   3102.19 30.2107 8.638e-09 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## 3     42 2513.8  1    667.13 12.9937 0.0008387 ***&lt;/span&gt;
&lt;span class="code-line"&gt;## 4     41 2105.0  1    408.75  7.9612 0.0073357 ** &lt;/span&gt;
&lt;span class="code-line"&gt;## ---&lt;/span&gt;
&lt;span class="code-line"&gt;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It appears that each model is a significant improvement on its predecessor.&lt;/p&gt;
&lt;!-- 
## Experimenting VIF high values

Regardless of your criterion for what constitutes a high VIF, there are at least three situations in which a high VIF is not a problem and can be safely ignored:

2. The high VIFs are caused by the inclusion of powers or products of other variables.

Sources
http://statisticalhorizons.com/multicollinearity
--&gt;</summary><category term="R"></category><category term="stats"></category><category term="regression"></category></entry><entry><title>R: Analysis of weather events impact on population health and economy.</title><link href="http://stephanie-w.github.io/blog/weather_event_impact.html" rel="alternate"></link><updated>2015-08-10T16:19:08+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-10:blog/weather_event_impact.html</id><summary type="html">&lt;hr /&gt;
&lt;h2 id="synopsis"&gt;Synopsis&lt;/h2&gt;
&lt;p&gt;This analysis involves exploring the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database. &lt;/p&gt;
&lt;p&gt;This database tracks characteristics of major storms and weather events in the United States, including when and where they occur, as well as estimates of any fatalities, injuries, and property damage.&lt;/p&gt;
&lt;p&gt;This analysis focuses on fatalities, injuries, property and crop damages to answer to the 2 following questions : 
Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
Across the United States, which types of events have the greatest economic consequences?&lt;/p&gt;
&lt;h2 id="data-processing"&gt;Data Processing&lt;/h2&gt;
&lt;p&gt;The data comes in the form of a comma-separated-value file compressed via the bzip2.&lt;/p&gt;
&lt;p&gt;We download it and unzip it in a ProjectData directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;download.file&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;FStormData.csv.bz2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    method &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;curl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; quiet &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;raw &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;bzfile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;FStormData.csv.bz2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; sep &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; quote &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; header &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; stringsAsFactors &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;BGN_DATE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;as.Date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;BGN_DATE&lt;span class="p"&gt;,&lt;/span&gt; format &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%m/%d/%Y %H:%M:%S&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;END_DATE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;as.Date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;END_DATE&lt;span class="p"&gt;,&lt;/span&gt; format &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%m/%d/%Y %H:%M:%S&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Storm Events Database reports that all weather events are only recorded since 1996 (see http://www.ncdc.noaa.gov/stormevents/details.jsp).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;    Event Types Available:&lt;/span&gt;
&lt;span class="code-line"&gt;    Add more info about event types here. Link to collections page/tab when referencing data collection source.&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    1. Tornado: From 1950 through 1954, only tornado events were recorded.&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    2. Tornado, Thunderstorm Wind and Hail: From 1955 through 1992, only tornado, thunderstorm wind and hail events were keyed from the paper publications into digital data. From 1993 to 1995, only tornado, thunderstorm wind and hail events have been extracted from the Unformatted Text Files.&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    3. All Event Types (48 from Directive 10-1605): From 1996 to present, 48 event types are recorded as defined in NWS Directive 10-1605.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since we're reporting impacts from various weather events, we'll focus our study on data since 1996.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;BGN_DATE &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1996-01-01&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;rm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="results"&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Weather events impact on population health across the United States since 1996&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To study the weather events impact on poulation health, we examine the INJURIES AND FATALITIES columns of the dataset.&lt;/p&gt;
&lt;p&gt;We compute the sum of total of injuries/fatalities by weather event type an store the values in a new dataset:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;fat_by_ev &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; aggregate&lt;span class="p"&gt;(&lt;/span&gt;FATALITIES &lt;span class="o"&gt;~&lt;/span&gt; EVTYPE&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; data&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; na.rm &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;inj_by_ev &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; aggregate&lt;span class="p"&gt;(&lt;/span&gt;INJURIES &lt;span class="o"&gt;~&lt;/span&gt; EVTYPE&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; data&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; na.rm &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For fatalities, the quantile function shows that only 1% of the values of the total of injuries/fatalities by event type are significant (&amp;gt; 326 fatalities, &amp;gt; 1635 injuries).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;quantile&lt;span class="p"&gt;(&lt;/span&gt;fat_by_ev&lt;span class="o"&gt;$&lt;/span&gt;FATALITIES&lt;span class="p"&gt;,&lt;/span&gt; probs &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%    100% &lt;/span&gt;
&lt;span class="code-line"&gt;##    4.00    5.74    9.88   14.02   28.80   57.90   78.08  105.32  198.92  326.14 1797.00&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;quantile&lt;span class="p"&gt;(&lt;/span&gt;inj_by_ev&lt;span class="o"&gt;$&lt;/span&gt;INJURIES&lt;span class="p"&gt;,&lt;/span&gt; probs &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##      90%      91%      92%      93%      94%      95%      96%      97%      98%      99%     100% &lt;/span&gt;
&lt;span class="code-line"&gt;##    21.60    25.74    39.76    70.04    85.76   171.90   304.56   477.80  1034.84  1635.64 20667.00&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We order the new datas by fatalities/injuries (decreasing order) and display the 10th first rows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;fat_temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; fat_by_ev&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;fat_by_ev&lt;span class="o"&gt;$&lt;/span&gt;FATALITIES&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;fat_temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;fatalities&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;inj_temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; inj_by_ev&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;inj_by_ev&lt;span class="o"&gt;$&lt;/span&gt;INJURIES&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;inj_temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;injuries&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;knitr&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;fat_temp&lt;span class="p"&gt;,&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total fatalities by weather event type since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;fatalities&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;75&lt;/td&gt;
&lt;td align="left"&gt;EXCESSIVE HEAT&lt;/td&gt;
&lt;td align="right"&gt;1797&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;417&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;1511&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;96&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;887&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;213&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;650&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;99&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;414&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;286&lt;/td&gt;
&lt;td align="left"&gt;RIP CURRENT&lt;/td&gt;
&lt;td align="right"&gt;340&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;423&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;241&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;143&lt;/td&gt;
&lt;td align="left"&gt;HEAT&lt;/td&gt;
&lt;td align="right"&gt;237&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;161&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;235&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;16&lt;/td&gt;
&lt;td align="left"&gt;AVALANCHE&lt;/td&gt;
&lt;td align="right"&gt;223&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;inj_temp&lt;span class="p"&gt;,&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total injuries by weather event type since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;injuries&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;417&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;20667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;99&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;6758&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;75&lt;/td&gt;
&lt;td align="left"&gt;EXCESSIVE HEAT&lt;/td&gt;
&lt;td align="right"&gt;6391&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;213&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;4140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;423&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;3629&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;96&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;1674&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;413&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;1400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;496&lt;/td&gt;
&lt;td align="left"&gt;WINTER STORM&lt;/td&gt;
&lt;td align="right"&gt;1292&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;167&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE/TYPHOON&lt;/td&gt;
&lt;td align="right"&gt;1275&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;143&lt;/td&gt;
&lt;td align="left"&gt;HEAT&lt;/td&gt;
&lt;td align="right"&gt;1222&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Then plot the datas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;fat_temp&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;reorder&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;event.type&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;fatalities&lt;span class="p"&gt;),&lt;/span&gt; fatalities&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;(&lt;/span&gt;stat &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;identity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Fatalities&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total fatalities by weather event type since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    theme&lt;span class="p"&gt;(&lt;/span&gt;axis.text.x &lt;span class="o"&gt;=&lt;/span&gt; element_text&lt;span class="p"&gt;(&lt;/span&gt;angle &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; hjust &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/weather_events_impact_fatalities-1.png" title="plot of chunk weather_events_impact_fatalities" alt="plot of chunk weather_events_impact_fatalities" class="plot" /&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;inj_temp&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;reorder&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;event.type&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;injuries&lt;span class="p"&gt;),&lt;/span&gt; injuries&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;(&lt;/span&gt;stat &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;identity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Injuries&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total injuries by weather event type since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    theme&lt;span class="p"&gt;(&lt;/span&gt;axis.text.x &lt;span class="o"&gt;=&lt;/span&gt; element_text&lt;span class="p"&gt;(&lt;/span&gt;angle &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; hjust &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/weather_events_impact_injuries-1.png" title="plot of chunk weather_events_impact_injuries" alt="plot of chunk weather_events_impact_injuries" class="plot" /&gt;&lt;/div&gt;

&lt;p&gt;To go deeper, we can examine single weather types by having a closer look on their frequency/injuries and fatalities ratio :&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;plyr&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;fat_ev_count &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;FATALITIES &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; vars &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;fat_ev_count&lt;span class="p"&gt;,&lt;/span&gt; fat_by_ev&lt;span class="p"&gt;,&lt;/span&gt; by &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;ratio &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; temp&lt;span class="o"&gt;$&lt;/span&gt;FATALITIES&lt;span class="o"&gt;/&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;freq&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.fatalities&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.fatalities.ratio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;event.frequency&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total fatalities by weather event type (ordered by frequency desc) since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;event.frequency&lt;/th&gt;
&lt;th align="right"&gt;event.fatalities&lt;/th&gt;
&lt;th align="right"&gt;event.fatalities.ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;63&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;608&lt;/td&gt;
&lt;td align="right"&gt;650&lt;/td&gt;
&lt;td align="right"&gt;1.069079&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;27&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;584&lt;/td&gt;
&lt;td align="right"&gt;887&lt;/td&gt;
&lt;td align="right"&gt;1.518836&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;20&lt;/td&gt;
&lt;td align="left"&gt;EXCESSIVE HEAT&lt;/td&gt;
&lt;td align="right"&gt;564&lt;/td&gt;
&lt;td align="right"&gt;1797&lt;/td&gt;
&lt;td align="right"&gt;3.186170&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;92&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;459&lt;/td&gt;
&lt;td align="right"&gt;1511&lt;/td&gt;
&lt;td align="right"&gt;3.291939&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;74&lt;/td&gt;
&lt;td align="left"&gt;RIP CURRENT&lt;/td&gt;
&lt;td align="right"&gt;301&lt;/td&gt;
&lt;td align="right"&gt;340&lt;/td&gt;
&lt;td align="right"&gt;1.129568&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;28&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;270&lt;/td&gt;
&lt;td align="right"&gt;414&lt;/td&gt;
&lt;td align="right"&gt;1.533333&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;94&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;212&lt;/td&gt;
&lt;td align="right"&gt;241&lt;/td&gt;
&lt;td align="right"&gt;1.136793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;75&lt;/td&gt;
&lt;td align="left"&gt;RIP CURRENTS&lt;/td&gt;
&lt;td align="right"&gt;179&lt;/td&gt;
&lt;td align="right"&gt;202&lt;/td&gt;
&lt;td align="right"&gt;1.128492&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;48&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;176&lt;/td&gt;
&lt;td align="right"&gt;235&lt;/td&gt;
&lt;td align="right"&gt;1.335227&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;AVALANCHE&lt;/td&gt;
&lt;td align="right"&gt;173&lt;/td&gt;
&lt;td align="right"&gt;223&lt;/td&gt;
&lt;td align="right"&gt;1.289017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;38&lt;/td&gt;
&lt;td align="left"&gt;HEAT&lt;/td&gt;
&lt;td align="right"&gt;133&lt;/td&gt;
&lt;td align="right"&gt;237&lt;/td&gt;
&lt;td align="right"&gt;1.781955&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;104&lt;/td&gt;
&lt;td align="left"&gt;WINTER STORM&lt;/td&gt;
&lt;td align="right"&gt;118&lt;/td&gt;
&lt;td align="right"&gt;191&lt;/td&gt;
&lt;td align="right"&gt;1.618644&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;90&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;107&lt;/td&gt;
&lt;td align="right"&gt;130&lt;/td&gt;
&lt;td align="right"&gt;1.214953&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;85&lt;/td&gt;
&lt;td align="left"&gt;STRONG WIND&lt;/td&gt;
&lt;td align="right"&gt;90&lt;/td&gt;
&lt;td align="right"&gt;103&lt;/td&gt;
&lt;td align="right"&gt;1.144444&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;22&lt;/td&gt;
&lt;td align="left"&gt;EXTREME COLD/WIND CHILL&lt;/td&gt;
&lt;td align="right"&gt;87&lt;/td&gt;
&lt;td align="right"&gt;125&lt;/td&gt;
&lt;td align="right"&gt;1.436782&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;21&lt;/td&gt;
&lt;td align="left"&gt;EXTREME COLD&lt;/td&gt;
&lt;td align="right"&gt;86&lt;/td&gt;
&lt;td align="right"&gt;113&lt;/td&gt;
&lt;td align="right"&gt;1.313953&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;41&lt;/td&gt;
&lt;td align="left"&gt;HEAVY SNOW&lt;/td&gt;
&lt;td align="right"&gt;75&lt;/td&gt;
&lt;td align="right"&gt;107&lt;/td&gt;
&lt;td align="right"&gt;1.426667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11&lt;/td&gt;
&lt;td align="left"&gt;COLD/WIND CHILL&lt;/td&gt;
&lt;td align="right"&gt;74&lt;/td&gt;
&lt;td align="right"&gt;95&lt;/td&gt;
&lt;td align="right"&gt;1.283784&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;45&lt;/td&gt;
&lt;td align="left"&gt;HIGH SURF&lt;/td&gt;
&lt;td align="right"&gt;63&lt;/td&gt;
&lt;td align="right"&gt;87&lt;/td&gt;
&lt;td align="right"&gt;1.380952&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;39&lt;/td&gt;
&lt;td align="left"&gt;HEAVY RAIN&lt;/td&gt;
&lt;td align="right"&gt;59&lt;/td&gt;
&lt;td align="right"&gt;94&lt;/td&gt;
&lt;td align="right"&gt;1.593220&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;58&lt;/td&gt;
&lt;td align="left"&gt;ICE STORM&lt;/td&gt;
&lt;td align="right"&gt;51&lt;/td&gt;
&lt;td align="right"&gt;82&lt;/td&gt;
&lt;td align="right"&gt;1.607843&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;BLIZZARD&lt;/td&gt;
&lt;td align="right"&gt;46&lt;/td&gt;
&lt;td align="right"&gt;70&lt;/td&gt;
&lt;td align="right"&gt;1.521739&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;29&lt;/td&gt;
&lt;td align="left"&gt;FOG&lt;/td&gt;
&lt;td align="right"&gt;35&lt;/td&gt;
&lt;td align="right"&gt;60&lt;/td&gt;
&lt;td align="right"&gt;1.714286&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;105&lt;/td&gt;
&lt;td align="left"&gt;WINTER WEATHER&lt;/td&gt;
&lt;td align="right"&gt;29&lt;/td&gt;
&lt;td align="right"&gt;33&lt;/td&gt;
&lt;td align="right"&gt;1.137931&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;101&lt;/td&gt;
&lt;td align="left"&gt;WILDFIRE&lt;/td&gt;
&lt;td align="right"&gt;28&lt;/td&gt;
&lt;td align="right"&gt;75&lt;/td&gt;
&lt;td align="right"&gt;2.678571&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;43&lt;/td&gt;
&lt;td align="left"&gt;HEAVY SURF/HIGH SURF&lt;/td&gt;
&lt;td align="right"&gt;27&lt;/td&gt;
&lt;td align="right"&gt;42&lt;/td&gt;
&lt;td align="right"&gt;1.555556&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;93&lt;/td&gt;
&lt;td align="left"&gt;TROPICAL STORM&lt;/td&gt;
&lt;td align="right"&gt;24&lt;/td&gt;
&lt;td align="right"&gt;57&lt;/td&gt;
&lt;td align="right"&gt;2.375000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;49&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE&lt;/td&gt;
&lt;td align="right"&gt;23&lt;/td&gt;
&lt;td align="right"&gt;61&lt;/td&gt;
&lt;td align="right"&gt;2.652174&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;98&lt;/td&gt;
&lt;td align="left"&gt;URBAN/SML STREAM FLD&lt;/td&gt;
&lt;td align="right"&gt;22&lt;/td&gt;
&lt;td align="right"&gt;28&lt;/td&gt;
&lt;td align="right"&gt;1.272727&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE/TYPHOON&lt;/td&gt;
&lt;td align="right"&gt;19&lt;/td&gt;
&lt;td align="right"&gt;64&lt;/td&gt;
&lt;td align="right"&gt;3.368421&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;inj_ev_count &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;INJURIES &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; vars &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;inj_ev_count&lt;span class="p"&gt;,&lt;/span&gt; inj_by_ev&lt;span class="p"&gt;,&lt;/span&gt; by &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;ratio &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; temp&lt;span class="o"&gt;$&lt;/span&gt;INJURIES&lt;span class="o"&gt;/&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;freq&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.injuries&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.injuries.ratio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;event.frequency&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total Injuries by weather event type (ordered by frequency desc) since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;event.frequency&lt;/th&gt;
&lt;th align="right"&gt;event.injuries&lt;/th&gt;
&lt;th align="right"&gt;event.injuries.ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;56&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;2250&lt;/td&gt;
&lt;td align="right"&gt;4140&lt;/td&gt;
&lt;td align="right"&gt;1.840000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;85&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;1877&lt;/td&gt;
&lt;td align="right"&gt;20667&lt;/td&gt;
&lt;td align="right"&gt;11.010655&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;87&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;1492&lt;/td&gt;
&lt;td align="right"&gt;3629&lt;/td&gt;
&lt;td align="right"&gt;2.432306&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;83&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;587&lt;/td&gt;
&lt;td align="right"&gt;1400&lt;/td&gt;
&lt;td align="right"&gt;2.385009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;43&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;403&lt;/td&gt;
&lt;td align="right"&gt;1083&lt;/td&gt;
&lt;td align="right"&gt;2.687345&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;23&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;335&lt;/td&gt;
&lt;td align="right"&gt;1674&lt;/td&gt;
&lt;td align="right"&gt;4.997015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;99&lt;/td&gt;
&lt;td align="left"&gt;WILDFIRE&lt;/td&gt;
&lt;td align="right"&gt;184&lt;/td&gt;
&lt;td align="right"&gt;911&lt;/td&gt;
&lt;td align="right"&gt;4.951087&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;34&lt;/td&gt;
&lt;td align="left"&gt;HAIL&lt;/td&gt;
&lt;td align="right"&gt;165&lt;/td&gt;
&lt;td align="right"&gt;713&lt;/td&gt;
&lt;td align="right"&gt;4.321212&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17&lt;/td&gt;
&lt;td align="left"&gt;EXCESSIVE HEAT&lt;/td&gt;
&lt;td align="right"&gt;162&lt;/td&gt;
&lt;td align="right"&gt;6391&lt;/td&gt;
&lt;td align="right"&gt;39.450617&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;79&lt;/td&gt;
&lt;td align="left"&gt;STRONG WIND&lt;/td&gt;
&lt;td align="right"&gt;147&lt;/td&gt;
&lt;td align="right"&gt;278&lt;/td&gt;
&lt;td align="right"&gt;1.891156&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;101&lt;/td&gt;
&lt;td align="left"&gt;WINTER STORM&lt;/td&gt;
&lt;td align="right"&gt;144&lt;/td&gt;
&lt;td align="right"&gt;1292&lt;/td&gt;
&lt;td align="right"&gt;8.972222&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;24&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;142&lt;/td&gt;
&lt;td align="right"&gt;6758&lt;/td&gt;
&lt;td align="right"&gt;47.591549&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;98&lt;/td&gt;
&lt;td align="left"&gt;WILD/FOREST FIRE&lt;/td&gt;
&lt;td align="right"&gt;130&lt;/td&gt;
&lt;td align="right"&gt;545&lt;/td&gt;
&lt;td align="right"&gt;4.192308&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;68&lt;/td&gt;
&lt;td align="left"&gt;RIP CURRENT&lt;/td&gt;
&lt;td align="right"&gt;107&lt;/td&gt;
&lt;td align="right"&gt;209&lt;/td&gt;
&lt;td align="right"&gt;1.953271&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;AVALANCHE&lt;/td&gt;
&lt;td align="right"&gt;105&lt;/td&gt;
&lt;td align="right"&gt;156&lt;/td&gt;
&lt;td align="right"&gt;1.485714&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;38&lt;/td&gt;
&lt;td align="left"&gt;HEAVY SNOW&lt;/td&gt;
&lt;td align="right"&gt;102&lt;/td&gt;
&lt;td align="right"&gt;698&lt;/td&gt;
&lt;td align="right"&gt;6.843137&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;69&lt;/td&gt;
&lt;td align="left"&gt;RIP CURRENTS&lt;/td&gt;
&lt;td align="right"&gt;84&lt;/td&gt;
&lt;td align="right"&gt;294&lt;/td&gt;
&lt;td align="right"&gt;3.500000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;25&lt;/td&gt;
&lt;td align="left"&gt;FOG&lt;/td&gt;
&lt;td align="right"&gt;73&lt;/td&gt;
&lt;td align="right"&gt;712&lt;/td&gt;
&lt;td align="right"&gt;9.753425&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;37&lt;/td&gt;
&lt;td align="left"&gt;HEAVY RAIN&lt;/td&gt;
&lt;td align="right"&gt;73&lt;/td&gt;
&lt;td align="right"&gt;230&lt;/td&gt;
&lt;td align="right"&gt;3.150685&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;51&lt;/td&gt;
&lt;td align="left"&gt;ICE STORM&lt;/td&gt;
&lt;td align="right"&gt;53&lt;/td&gt;
&lt;td align="right"&gt;318&lt;/td&gt;
&lt;td align="right"&gt;6.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;BLIZZARD&lt;/td&gt;
&lt;td align="right"&gt;41&lt;/td&gt;
&lt;td align="right"&gt;385&lt;/td&gt;
&lt;td align="right"&gt;9.390244&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15&lt;/td&gt;
&lt;td align="left"&gt;DUST STORM&lt;/td&gt;
&lt;td align="right"&gt;38&lt;/td&gt;
&lt;td align="right"&gt;376&lt;/td&gt;
&lt;td align="right"&gt;9.894737&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;36&lt;/td&gt;
&lt;td align="left"&gt;HEAT&lt;/td&gt;
&lt;td align="right"&gt;36&lt;/td&gt;
&lt;td align="right"&gt;1222&lt;/td&gt;
&lt;td align="right"&gt;33.944444&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;42&lt;/td&gt;
&lt;td align="left"&gt;HIGH SURF&lt;/td&gt;
&lt;td align="right"&gt;33&lt;/td&gt;
&lt;td align="right"&gt;146&lt;/td&gt;
&lt;td align="right"&gt;4.424242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;102&lt;/td&gt;
&lt;td align="left"&gt;WINTER WEATHER&lt;/td&gt;
&lt;td align="right"&gt;30&lt;/td&gt;
&lt;td align="right"&gt;343&lt;/td&gt;
&lt;td align="right"&gt;11.433333&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;90&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND/HAIL&lt;/td&gt;
&lt;td align="right"&gt;26&lt;/td&gt;
&lt;td align="right"&gt;95&lt;/td&gt;
&lt;td align="right"&gt;3.653846&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;95&lt;/td&gt;
&lt;td align="left"&gt;URBAN/SML STREAM FLD&lt;/td&gt;
&lt;td align="right"&gt;26&lt;/td&gt;
&lt;td align="right"&gt;79&lt;/td&gt;
&lt;td align="right"&gt;3.038461&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;100&lt;/td&gt;
&lt;td align="left"&gt;WIND&lt;/td&gt;
&lt;td align="right"&gt;26&lt;/td&gt;
&lt;td align="right"&gt;84&lt;/td&gt;
&lt;td align="right"&gt;3.230769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;86&lt;/td&gt;
&lt;td align="left"&gt;TROPICAL STORM&lt;/td&gt;
&lt;td align="right"&gt;23&lt;/td&gt;
&lt;td align="right"&gt;338&lt;/td&gt;
&lt;td align="right"&gt;14.695652&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;11&lt;/td&gt;
&lt;td align="left"&gt;DENSE FOG&lt;/td&gt;
&lt;td align="right"&gt;20&lt;/td&gt;
&lt;td align="right"&gt;143&lt;/td&gt;
&lt;td align="right"&gt;7.150000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Weather events economic impact across Unites States&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We'll examine the property and crop damages columns (PROPDMG * 10^PROPDMGEXP and CROPDMG * 10^CROPDMGEXP, respectively) from the dataset.&lt;/p&gt;
&lt;p&gt;We need to preprocess the data to convert PROPDMG and PROPDMGEXP into numbers, idem for CROPDMG and CROPDMGEXP.&lt;/p&gt;
&lt;p&gt;Values for the CROPDMGEXP and PROPDMEXP are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0 or blank&lt;/li&gt;
&lt;li&gt;H for Hundred&lt;/li&gt;
&lt;li&gt;K for Thousand&lt;/li&gt;
&lt;li&gt;M for Million&lt;/li&gt;
&lt;li&gt;B for Billion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: Except for these exponential values (H,K,M,B), there is some inexpected values : ? + - and numbers in the initial dataset. This values doesn't appear in the dataset filtered by BGN_DATE &amp;gt; 1996-01-01.&lt;/p&gt;
&lt;p&gt;Let's check the repartition of the exponential categories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kp"&gt;table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;CROPDMGEXP&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;##             B      K      M &lt;/span&gt;
&lt;span class="code-line"&gt;## 373047      4 278685   1771&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kp"&gt;table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;PROPDMGEXP&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## &lt;/span&gt;
&lt;span class="code-line"&gt;##             0      B      K      M &lt;/span&gt;
&lt;span class="code-line"&gt;## 276166      1     32 369934   7374&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We convert PROPDMG/PROPDMGEXP and CROPDMG/CROPDMGEXP pairs into numbers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;data&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.exp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;CROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;H&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cropdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;CROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;K&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cropdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1000&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;CROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;M&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cropdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;CROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;B&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cropdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="m"&gt;9&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.val &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data&lt;span class="o"&gt;$&lt;/span&gt;CROPDMG &lt;span class="o"&gt;*&lt;/span&gt; data&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.exp&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="o"&gt;$&lt;/span&gt;propdmg.exp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;PROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;H&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;propdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;PROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;K&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;propdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1000&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;PROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;M&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;propdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1e+06&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;PROPDMGEXP &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;B&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;propdmg.exp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1e+09&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;data&lt;span class="o"&gt;$&lt;/span&gt;propdmg.val &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data&lt;span class="o"&gt;$&lt;/span&gt;PROPDMG &lt;span class="o"&gt;*&lt;/span&gt; data&lt;span class="o"&gt;$&lt;/span&gt;propdmg.exp&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We perform the same analysis as for weather type impact on population health:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;crop_by_ev &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; aggregate&lt;span class="p"&gt;(&lt;/span&gt;cropdmg.val &lt;span class="o"&gt;~&lt;/span&gt; EVTYPE&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; data&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; na.rm &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;quantile&lt;span class="p"&gt;(&lt;/span&gt;crop_by_ev&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.val&lt;span class="p"&gt;,&lt;/span&gt; probs &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##         90%         91%         92%         93%         94%         95%         96%         97% &lt;/span&gt;
&lt;span class="code-line"&gt;##       80000      522000     1830000     8518338    15105600    22067850    51986350   225801006 &lt;/span&gt;
&lt;span class="code-line"&gt;##         98%         99%        100% &lt;/span&gt;
&lt;span class="code-line"&gt;##   611260434  1328471682 13367566000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;prop_by_ev &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; aggregate&lt;span class="p"&gt;(&lt;/span&gt;propdmg.val &lt;span class="o"&gt;~&lt;/span&gt; EVTYPE&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; data&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; na.rm &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;quantile&lt;span class="p"&gt;(&lt;/span&gt;prop_by_ev&lt;span class="o"&gt;$&lt;/span&gt;propdmg.val&lt;span class="p"&gt;,&lt;/span&gt; probs &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##          90%          91%          92%          93%          94%          95%          96% &lt;/span&gt;
&lt;span class="code-line"&gt;##      6087080      7928162      9823200     19765792     40787880    117527100    551709366 &lt;/span&gt;
&lt;span class="code-line"&gt;##          97%          98%          99%         100% &lt;/span&gt;
&lt;span class="code-line"&gt;##   1328347705   4595502763  14205618003 143944833550&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;crop_temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; crop_by_ev&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;crop_by_ev&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.val&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;crop_temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cropdmg.val&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;prop_temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; prop_by_ev&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;prop_by_ev&lt;span class="o"&gt;$&lt;/span&gt;propdmg.val&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;prop_temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;propdmg.val&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;crop_temp&lt;span class="p"&gt;,&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total crop damages in (US dollars) by weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;cropdmg.val&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;59&lt;/td&gt;
&lt;td align="left"&gt;DROUGHT&lt;/td&gt;
&lt;td align="right"&gt;13367566000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;99&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;4974778400&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;166&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE&lt;/td&gt;
&lt;td align="right"&gt;2741410000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;167&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE/TYPHOON&lt;/td&gt;
&lt;td align="right"&gt;2607872800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;139&lt;/td&gt;
&lt;td align="left"&gt;HAIL&lt;/td&gt;
&lt;td align="right"&gt;2476029450&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;96&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;1334901700&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;81&lt;/td&gt;
&lt;td align="left"&gt;EXTREME COLD&lt;/td&gt;
&lt;td align="right"&gt;1288973000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;108&lt;/td&gt;
&lt;td align="left"&gt;FROST/FREEZE&lt;/td&gt;
&lt;td align="right"&gt;1094086000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;145&lt;/td&gt;
&lt;td align="left"&gt;HEAVY RAIN&lt;/td&gt;
&lt;td align="right"&gt;728169800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;420&lt;/td&gt;
&lt;td align="left"&gt;TROPICAL STORM&lt;/td&gt;
&lt;td align="right"&gt;677711000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;161&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;633561300&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;423&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;553915350&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;75&lt;/td&gt;
&lt;td align="left"&gt;EXCESSIVE HEAT&lt;/td&gt;
&lt;td align="right"&gt;492402000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;413&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;398331000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;487&lt;/td&gt;
&lt;td align="left"&gt;WILDFIRE&lt;/td&gt;
&lt;td align="right"&gt;295472800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;417&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;283425010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;102&lt;/td&gt;
&lt;td align="left"&gt;FREEZE&lt;/td&gt;
&lt;td align="right"&gt;146225000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;486&lt;/td&gt;
&lt;td align="left"&gt;WILD/FOREST FIRE&lt;/td&gt;
&lt;td align="right"&gt;106782330&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;150&lt;/td&gt;
&lt;td align="left"&gt;HEAVY SNOW&lt;/td&gt;
&lt;td align="right"&gt;71122100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;330&lt;/td&gt;
&lt;td align="left"&gt;STRONG WIND&lt;/td&gt;
&lt;td align="right"&gt;64953500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;prop_temp&lt;span class="p"&gt;,&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total property damages (in US dollars) by weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;propdmg.val&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;99&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;143944833550&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;167&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE/TYPHOON&lt;/td&gt;
&lt;td align="right"&gt;69305840000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;327&lt;/td&gt;
&lt;td align="left"&gt;STORM SURGE&lt;/td&gt;
&lt;td align="right"&gt;43193536000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;417&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;24616905710&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;96&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;15222203910&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;139&lt;/td&gt;
&lt;td align="left"&gt;HAIL&lt;/td&gt;
&lt;td align="right"&gt;14595143420&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;166&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE&lt;/td&gt;
&lt;td align="right"&gt;11812819010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;420&lt;/td&gt;
&lt;td align="left"&gt;TROPICAL STORM&lt;/td&gt;
&lt;td align="right"&gt;7642475550&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;161&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;5247860360&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;487&lt;/td&gt;
&lt;td align="left"&gt;WILDFIRE&lt;/td&gt;
&lt;td align="right"&gt;4758667000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;328&lt;/td&gt;
&lt;td align="left"&gt;STORM SURGE/TIDE&lt;/td&gt;
&lt;td align="right"&gt;4641188000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;423&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;4478026440&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;191&lt;/td&gt;
&lt;td align="left"&gt;ICE STORM&lt;/td&gt;
&lt;td align="right"&gt;3642248810&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;413&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;3382654440&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;486&lt;/td&gt;
&lt;td align="left"&gt;WILD/FOREST FIRE&lt;/td&gt;
&lt;td align="right"&gt;3001782500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;496&lt;/td&gt;
&lt;td align="left"&gt;WINTER STORM&lt;/td&gt;
&lt;td align="right"&gt;1532733250&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;59&lt;/td&gt;
&lt;td align="left"&gt;DROUGHT&lt;/td&gt;
&lt;td align="right"&gt;1046101000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;213&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;743077080&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;150&lt;/td&gt;
&lt;td align="left"&gt;HEAVY SNOW&lt;/td&gt;
&lt;td align="right"&gt;634417540&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;437&lt;/td&gt;
&lt;td align="left"&gt;TYPHOON&lt;/td&gt;
&lt;td align="right"&gt;600230000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;crop_temp&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;reorder&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;event.type&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;cropdmg.val&lt;span class="p"&gt;),&lt;/span&gt; cropdmg.val&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;(&lt;/span&gt;stat &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;identity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Crop damages in US dollars&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total Crop damages by weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    theme&lt;span class="p"&gt;(&lt;/span&gt;axis.text.x &lt;span class="o"&gt;=&lt;/span&gt; element_text&lt;span class="p"&gt;(&lt;/span&gt;angle &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; hjust &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/weather_events_impact_crop_damages-1.png" title="plot of chunk weather_events_impact_crop_damages" alt="plot of chunk weather_events_impact_crop_damages" class="plot" /&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;prop_temp&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;reorder&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;event.type&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;propdmg.val&lt;span class="p"&gt;),&lt;/span&gt; propdmg.val&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;(&lt;/span&gt;stat &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;identity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Weather event type type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Properties damages in US dollars&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total Properties damages by weather event type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    theme&lt;span class="p"&gt;(&lt;/span&gt;axis.text.x &lt;span class="o"&gt;=&lt;/span&gt; element_text&lt;span class="p"&gt;(&lt;/span&gt;angle &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; hjust &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/weather_events_impact_properties_damages-1.png" title="plot of chunk weather_events_impact_properties_damages" alt="plot of chunk weather_events_impact_properties_damages" class="plot" /&gt;&lt;/div&gt;

&lt;p&gt;and we check damages ratio by event type:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;crop_ev_count &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.val &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; vars &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;crop_ev_count&lt;span class="p"&gt;,&lt;/span&gt; crop_by_ev&lt;span class="p"&gt;,&lt;/span&gt; by &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;ratio &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; temp&lt;span class="o"&gt;$&lt;/span&gt;cropdmg.val&lt;span class="o"&gt;/&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;freq&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.cropdamages&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.cropdamages.ratio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;event.frequency&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total crop domages (in US dollars) by weather event type (ordered by frequency desc) since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;event.frequency&lt;/th&gt;
&lt;th align="right"&gt;event.cropdamages&lt;/th&gt;
&lt;th align="right"&gt;event.cropdamages.ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;22&lt;/td&gt;
&lt;td align="left"&gt;HAIL&lt;/td&gt;
&lt;td align="right"&gt;8100&lt;/td&gt;
&lt;td align="right"&gt;2476029450&lt;/td&gt;
&lt;td align="right"&gt;305682.65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;46&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;3440&lt;/td&gt;
&lt;td align="right"&gt;553915350&lt;/td&gt;
&lt;td align="right"&gt;161021.90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;14&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;1845&lt;/td&gt;
&lt;td align="right"&gt;1334901700&lt;/td&gt;
&lt;td align="right"&gt;723523.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;15&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;1599&lt;/td&gt;
&lt;td align="right"&gt;4974778400&lt;/td&gt;
&lt;td align="right"&gt;3111180.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;44&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;1254&lt;/td&gt;
&lt;td align="right"&gt;283425010&lt;/td&gt;
&lt;td align="right"&gt;226016.75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;43&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;924&lt;/td&gt;
&lt;td align="right"&gt;398331000&lt;/td&gt;
&lt;td align="right"&gt;431094.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4&lt;/td&gt;
&lt;td align="left"&gt;DROUGHT&lt;/td&gt;
&lt;td align="right"&gt;243&lt;/td&gt;
&lt;td align="right"&gt;13367566000&lt;/td&gt;
&lt;td align="right"&gt;55010559.67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;27&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;200&lt;/td&gt;
&lt;td align="right"&gt;633561300&lt;/td&gt;
&lt;td align="right"&gt;3167806.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;25&lt;/td&gt;
&lt;td align="left"&gt;HEAVY RAIN&lt;/td&gt;
&lt;td align="right"&gt;123&lt;/td&gt;
&lt;td align="right"&gt;728169800&lt;/td&gt;
&lt;td align="right"&gt;5920079.67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;53&lt;/td&gt;
&lt;td align="left"&gt;URBAN/SML STREAM FLD&lt;/td&gt;
&lt;td align="right"&gt;112&lt;/td&gt;
&lt;td align="right"&gt;8488100&lt;/td&gt;
&lt;td align="right"&gt;75786.61&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;17&lt;/td&gt;
&lt;td align="left"&gt;FROST/FREEZE&lt;/td&gt;
&lt;td align="right"&gt;102&lt;/td&gt;
&lt;td align="right"&gt;1094086000&lt;/td&gt;
&lt;td align="right"&gt;10726333.33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;42&lt;/td&gt;
&lt;td align="left"&gt;STRONG WIND&lt;/td&gt;
&lt;td align="right"&gt;94&lt;/td&gt;
&lt;td align="right"&gt;64953500&lt;/td&gt;
&lt;td align="right"&gt;690994.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;47&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND/HAIL&lt;/td&gt;
&lt;td align="right"&gt;89&lt;/td&gt;
&lt;td align="right"&gt;64696250&lt;/td&gt;
&lt;td align="right"&gt;726924.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;56&lt;/td&gt;
&lt;td align="left"&gt;WILDFIRE&lt;/td&gt;
&lt;td align="right"&gt;89&lt;/td&gt;
&lt;td align="right"&gt;295472800&lt;/td&gt;
&lt;td align="right"&gt;3319919.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;33&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;74&lt;/td&gt;
&lt;td align="right"&gt;6898440&lt;/td&gt;
&lt;td align="right"&gt;93222.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;45&lt;/td&gt;
&lt;td align="left"&gt;TROPICAL STORM&lt;/td&gt;
&lt;td align="right"&gt;59&lt;/td&gt;
&lt;td align="right"&gt;677711000&lt;/td&gt;
&lt;td align="right"&gt;11486627.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;28&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE&lt;/td&gt;
&lt;td align="right"&gt;47&lt;/td&gt;
&lt;td align="right"&gt;2741410000&lt;/td&gt;
&lt;td align="right"&gt;58327872.34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;9&lt;/td&gt;
&lt;td align="left"&gt;EXTREME COLD&lt;/td&gt;
&lt;td align="right"&gt;46&lt;/td&gt;
&lt;td align="right"&gt;1288973000&lt;/td&gt;
&lt;td align="right"&gt;28021152.17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;55&lt;/td&gt;
&lt;td align="left"&gt;WILD/FOREST FIRE&lt;/td&gt;
&lt;td align="right"&gt;35&lt;/td&gt;
&lt;td align="right"&gt;106782330&lt;/td&gt;
&lt;td align="right"&gt;3050923.71&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;29&lt;/td&gt;
&lt;td align="left"&gt;HURRICANE/TYPHOON&lt;/td&gt;
&lt;td align="right"&gt;33&lt;/td&gt;
&lt;td align="right"&gt;2607872800&lt;/td&gt;
&lt;td align="right"&gt;79026448.48&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;prop_ev_count &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;data&lt;span class="o"&gt;$&lt;/span&gt;propdmg.val &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; vars &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;prop_ev_count&lt;span class="p"&gt;,&lt;/span&gt; prop_by_ev&lt;span class="p"&gt;,&lt;/span&gt; by &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EVTYPE&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;ratio &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; temp&lt;span class="o"&gt;$&lt;/span&gt;propdmg.val&lt;span class="o"&gt;/&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;freq&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;event.type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.propdamages&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;event.propdamages.ratio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;kable&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;temp&lt;span class="o"&gt;$&lt;/span&gt;event.frequency&lt;span class="p"&gt;,&lt;/span&gt; decreasing &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;],&lt;/span&gt; caption &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total property damages (in US dollars) by weather event type (ordered by frequency desc) since 1996&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;event.type&lt;/th&gt;
&lt;th align="right"&gt;event.frequency&lt;/th&gt;
&lt;th align="right"&gt;event.propdamages&lt;/th&gt;
&lt;th align="right"&gt;event.propdamages.ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;142&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND&lt;/td&gt;
&lt;td align="right"&gt;60331&lt;/td&gt;
&lt;td align="right"&gt;4478026440&lt;/td&gt;
&lt;td align="right"&gt;74224.30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;137&lt;/td&gt;
&lt;td align="left"&gt;THUNDERSTORM WIND&lt;/td&gt;
&lt;td align="right"&gt;42726&lt;/td&gt;
&lt;td align="right"&gt;3382654440&lt;/td&gt;
&lt;td align="right"&gt;79170.87&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;65&lt;/td&gt;
&lt;td align="left"&gt;HAIL&lt;/td&gt;
&lt;td align="right"&gt;20002&lt;/td&gt;
&lt;td align="right"&gt;14595143420&lt;/td&gt;
&lt;td align="right"&gt;729684.20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;39&lt;/td&gt;
&lt;td align="left"&gt;FLASH FLOOD&lt;/td&gt;
&lt;td align="right"&gt;18647&lt;/td&gt;
&lt;td align="right"&gt;15222203910&lt;/td&gt;
&lt;td align="right"&gt;816335.28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;139&lt;/td&gt;
&lt;td align="left"&gt;TORNADO&lt;/td&gt;
&lt;td align="right"&gt;11847&lt;/td&gt;
&lt;td align="right"&gt;24616905710&lt;/td&gt;
&lt;td align="right"&gt;2077902.06&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;41&lt;/td&gt;
&lt;td align="left"&gt;FLOOD&lt;/td&gt;
&lt;td align="right"&gt;9086&lt;/td&gt;
&lt;td align="right"&gt;143944833550&lt;/td&gt;
&lt;td align="right"&gt;15842486.63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;96&lt;/td&gt;
&lt;td align="left"&gt;LIGHTNING&lt;/td&gt;
&lt;td align="right"&gt;8744&lt;/td&gt;
&lt;td align="right"&gt;743077080&lt;/td&gt;
&lt;td align="right"&gt;84981.37&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;74&lt;/td&gt;
&lt;td align="left"&gt;HIGH WIND&lt;/td&gt;
&lt;td align="right"&gt;5217&lt;/td&gt;
&lt;td align="right"&gt;5247860360&lt;/td&gt;
&lt;td align="right"&gt;1005915.35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;131&lt;/td&gt;
&lt;td align="left"&gt;STRONG WIND&lt;/td&gt;
&lt;td align="right"&gt;3206&lt;/td&gt;
&lt;td align="right"&gt;174741450&lt;/td&gt;
&lt;td align="right"&gt;54504.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;166&lt;/td&gt;
&lt;td align="left"&gt;WINTER STORM&lt;/td&gt;
&lt;td align="right"&gt;1344&lt;/td&gt;
&lt;td align="right"&gt;1532733250&lt;/td&gt;
&lt;td align="right"&gt;1140426.53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;68&lt;/td&gt;
&lt;td align="left"&gt;HEAVY SNOW&lt;/td&gt;
&lt;td align="right"&gt;943&lt;/td&gt;
&lt;td align="right"&gt;634417540&lt;/td&gt;
&lt;td align="right"&gt;672765.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;67&lt;/td&gt;
&lt;td align="left"&gt;HEAVY RAIN&lt;/td&gt;
&lt;td align="right"&gt;906&lt;/td&gt;
&lt;td align="right"&gt;584864440&lt;/td&gt;
&lt;td align="right"&gt;645545.74&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;163&lt;/td&gt;
&lt;td align="left"&gt;WILDFIRE&lt;/td&gt;
&lt;td align="right"&gt;723&lt;/td&gt;
&lt;td align="right"&gt;4758667000&lt;/td&gt;
&lt;td align="right"&gt;6581835.41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;157&lt;/td&gt;
&lt;td align="left"&gt;URBAN/SML STREAM FLD&lt;/td&gt;
&lt;td align="right"&gt;670&lt;/td&gt;
&lt;td align="right"&gt;58309650&lt;/td&gt;
&lt;td align="right"&gt;87029.33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;84&lt;/td&gt;
&lt;td align="left"&gt;ICE STORM&lt;/td&gt;
&lt;td align="right"&gt;594&lt;/td&gt;
&lt;td align="right"&gt;3642248810&lt;/td&gt;
&lt;td align="right"&gt;6131732.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;141&lt;/td&gt;
&lt;td align="left"&gt;TROPICAL STORM&lt;/td&gt;
&lt;td align="right"&gt;390&lt;/td&gt;
&lt;td align="right"&gt;7642475550&lt;/td&gt;
&lt;td align="right"&gt;19596091.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;152&lt;/td&gt;
&lt;td align="left"&gt;TSTM WIND/HAIL&lt;/td&gt;
&lt;td align="right"&gt;380&lt;/td&gt;
&lt;td align="right"&gt;44320500&lt;/td&gt;
&lt;td align="right"&gt;116632.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;167&lt;/td&gt;
&lt;td align="left"&gt;WINTER WEATHER&lt;/td&gt;
&lt;td align="right"&gt;373&lt;/td&gt;
&lt;td align="right"&gt;20866000&lt;/td&gt;
&lt;td align="right"&gt;55941.02&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;162&lt;/td&gt;
&lt;td align="left"&gt;WILD/FOREST FIRE&lt;/td&gt;
&lt;td align="right"&gt;303&lt;/td&gt;
&lt;td align="right"&gt;3001782500&lt;/td&gt;
&lt;td align="right"&gt;9906872.94&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;88&lt;/td&gt;
&lt;td align="left"&gt;LAKE-EFFECT SNOW&lt;/td&gt;
&lt;td align="right"&gt;194&lt;/td&gt;
&lt;td align="right"&gt;40115000&lt;/td&gt;
&lt;td align="right"&gt;206778.35&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="conclusions"&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Wheater events impact on population health&lt;/em&gt;
Our analysys shows that since 1996:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The "Tornado" event caused the most injuries&lt;/li&gt;
&lt;li&gt;Both the "Tornado" and "Excessive heat" events caused the most fatalities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the frequency/ratio table, we can notice that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The "Lightning", "Flash Flood" and "Excessive Heat" are the most frequent events regarding events causing fatalities&lt;/li&gt;
&lt;li&gt;The "Lightning", "Tornado" and "TSM Wind" are the most frequent events regarding events causing injuries&lt;/li&gt;
&lt;li&gt;The "Excessive heat", "Flood" and "Heat", have a very high ratio regarding injuries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Wheater events impact on economy&lt;/em&gt;
Our analysys shows that since 1996:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The "Drought" event caused the most crop damages&lt;/li&gt;
&lt;li&gt;The "Flood" events caused the most property damages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the frequency/ratio table, we can notice that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The "Hail" event is the most frequent event regarding events causing crop damages&lt;/li&gt;
&lt;li&gt;The "TSTM Wind" event is the most frequent event regarding events causing property damages&lt;/li&gt;
&lt;li&gt;The "Drought" and "Hurricane" events have a very high crop damages ratio&lt;/li&gt;
&lt;li&gt;The "Flood" and "Tropical storm" events have a very high property damages ratio&lt;/li&gt;
&lt;/ul&gt;</summary><category term="R"></category></entry><entry><title>Hadoop: Word Count Code explained</title><link href="http://stephanie-w.github.io/blog/word-count-explained.html" rel="alternate"></link><updated>2015-08-10T16:19:08+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-10:blog/word-count-explained.html</id><summary type="html">&lt;hr /&gt;




&lt;p&gt;Map Reduce Data Flow Diagram&lt;/p&gt;
&lt;p&gt;&lt;img alt="Map Reduce WordCount Diagram" src="figure/wordcount.png" /&gt;&lt;/p&gt;
&lt;h2 id="mapper-code"&gt;Mapper Code&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.IOException&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.StringTokenizer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.IntWritable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.LongWritable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.Text&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.MapReduceBase&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.Mapper&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.OutputCollector&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.Reporter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;WordCountMapper&lt;/span&gt; &lt;span class="n"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;MapReduceBase&lt;/span&gt; &lt;span class="n"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;Mapper&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;LongWritable&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The mapper class (WordCountMapper) is static and extends MapReduceBase and implements Mapper.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The variable &lt;code&gt;one&lt;/code&gt; of IntWritable type is initialized to one. The variables &lt;code&gt;one&lt;/code&gt; and &lt;code&gt;word&lt;/code&gt; are the key/value pair respectively.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;map&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LongWritable&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;OutputCollector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Reporter&lt;/span&gt; &lt;span class="n"&gt;reporter&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The map method takes as parameters a LongWritable, which is the key, a text, which is the value and a OutputCollector which takes a Text and IntWritable output, then the reporter for status reporting.
It throws a file exception if the file can't be acceeses for some reason.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toString&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;StringTokenizer&lt;/span&gt; &lt;span class="n"&gt;itr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;StringTokenizer&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toLowerCase&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The SringTokenizer class is a utility class in the MapReduceAPI that breaks down line into words. That's the defaut method fo tokenize lines. But Many times, in production context, this class will be extended or replaced.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;itr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hasMoreTokens&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;set&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;itr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;nextToken&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;collect&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While the tokenizer has still tokens, take the word and set the tokenizer to the next token. Then collect &lt;code&gt;word&lt;/code&gt; and &lt;code&gt;one&lt;/code&gt; in the output collector.&lt;/p&gt;
&lt;p&gt;This code is runned on each of the physical nodes and takes chunks of text from the HDFS file system by default and break them into a set of key/value pairs (ie. word and one)&lt;/p&gt;
&lt;h2 id="reducer-code"&gt;Reducer Code&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.IOException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.Iterator&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.IntWritable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.Text&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.WritableComparable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.MapReduceBase&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.OutputCollector&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.Reducer&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.Reporter&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;WordCountReducer&lt;/span&gt; &lt;span class="kd"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;MapReduceBase&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;Reducer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Reduce class &lt;code&gt;WordCountReducer&lt;/code&gt; extends MapReduceBase and implements a reducer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;reduce&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Iterator&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;OutputCollector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Reporter&lt;/span&gt; &lt;span class="n"&gt;reporter&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;hasNext&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="c1"&gt;// replace ValueType with the real type of your value&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="n"&gt;IntWritable&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;next&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// process value&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;collect&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The reducer aggregates or counts up the number of word of each type. Then collect the key and sum in the output collector, producing smaller summary of word count.&lt;/p&gt;
&lt;p&gt;All the values with the same key are presented to a single reducer together.
The reducer receives a key and an iterator of input values from an input list, returning a single output value.&lt;/p&gt;
&lt;p&gt;To resume:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;mapper(filename, file-contents):&lt;/span&gt;
&lt;span class="code-line"&gt;  for each word in file-contents:&lt;/span&gt;
&lt;span class="code-line"&gt;    emit (word, 1)&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;reducer(word values):&lt;/span&gt;
&lt;span class="code-line"&gt;  sum = 0&lt;/span&gt;
&lt;span class="code-line"&gt;  for each value in values:&lt;/span&gt;
&lt;span class="code-line"&gt;sum = sum + value&lt;/span&gt;
&lt;span class="code-line"&gt;emit(word, sum)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="driver-code"&gt;Driver Code&lt;/h2&gt;
&lt;p&gt;The mapreduce code is runned by a main method, called the Driver.
The driver initializes the job and instructs the Hadoop platform to execute the code on a set of input files, and controls where the output files are placed.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.fs.Path&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.IntWritable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.io.Text&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.FileInputFormat&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.FileOutputFormat&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.JobClient&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.hadoop.mapred.JobConf&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;WordCount&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Create an instance of job configuration that parse the WordCount.class:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="n"&gt;JobClient&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;JobClient&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;JobConf&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;JobConf&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;WordCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Specify output types:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setOutputKeyClass&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setOutputValueClass&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IntWritable&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Specify input and output directories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="n"&gt;FileInputFormat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;addInputPath&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;input&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;  &lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;FileOutputFormat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setOutputPath&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;output&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Specify a mapper:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setMapperClass&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;WordCountMapper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Specify a reducer:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setReducerClass&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;WordCountReducer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setCombinerClass&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;WordCountReducer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setConf&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the Job by submitting the job to Mapreduce:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="n"&gt;JobClient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;runJob&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Exception&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;            &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;printStackTrace&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="high-level-mapreduce-pipeline"&gt;High level MapReduce Pipeline&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="https://farm4.static.flickr.com/3126/3529146657_5b5d025a5f_o.png" /&gt;&lt;/p&gt;
&lt;p&gt;In details:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://farm3.static.flickr.com/2275/3529146683_c8247ff6db_o.png" /&gt;&lt;/p&gt;
&lt;p&gt;The read and split up of input files are defined by the InputFormat which performs the following tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selects the files or other objects that should be used for input&lt;/li&gt;
&lt;li&gt;Defines the InputSplits that break a file into tasks&lt;/li&gt;
&lt;li&gt;Provides a factory for RecordReader objects that read the file&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Standard InputFormat are :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;InputFormat&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Key&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TextInputFormat&lt;/td&gt;
&lt;td&gt;Default format;&lt;br&gt;reads lines of text files&lt;/td&gt;
&lt;td&gt;The byte offset of the line&lt;/td&gt;
&lt;td&gt;The line contents&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;KeyValueInputFormat&lt;/td&gt;
&lt;td&gt;Parses lines into key,&lt;br&gt; val pair&lt;/td&gt;
&lt;td&gt;Everything up to the first tab character&lt;/td&gt;
&lt;td&gt;The remainder of the line&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SequenceFileInputFormat&lt;/td&gt;
&lt;td&gt;A Hadoop-specific high-performance binary format&lt;/td&gt;
&lt;td&gt;user-defined&lt;/td&gt;
&lt;td&gt;user-defined&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The InputSplit describes a unit of work that comprises a single map task in a MapReduce program.&lt;br /&gt;
By processing a file in chunks, several map tasks can operate on a single file in parallel. Since the various blocks that make up the file may be spread across several different nodes in the cluster, tasks can be scheduled on each of these different node.&lt;br /&gt;
The RecordReader class loads the data from its source and converts it into (key, value) pairs suitable for reading by the Mapper. The key associated with each line is its byte offset in the file. The RecordReader is invoke repeatedly on the input until the entire InputSplit has been consumed.&lt;/p&gt;
&lt;p&gt;After the mapping process, the (intermediate) outputs are moved to the reducers (shuffling). A different subset of the intermediate key space is assigned to each reduce node; these subsets (known as "partitions") are the inputs to the reduce tasks. The map nodes must all agree on where to send the different pieces of the intermediate data. The Partitioner class determines which partition a given (key, value) pair will go to.&lt;/p&gt;
&lt;p&gt;Each reduce task is responsible for reducing the values associated with several intermediate keys. The set of intermediate keys on a single node is automatically sorted by Hadoop before they are presented to the Reducer.&lt;/p&gt;
&lt;p&gt;After the reducing process the (key, value) pairs provided to this OutputCollector are then written to output files.&lt;br /&gt;
iThe instances of OutputFormat provided by Hadoop write to files on the local disk or in HDFS; they all inherit from a common FileOutputFormat. Each Reducer writes a separate file in a common output directory (usually named part-nnn).  &lt;/p&gt;
&lt;p&gt;Standard OutputFormat are:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;OutputFormat&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TextOutputFormat&lt;/td&gt;
&lt;td&gt;Default; writes lines in "key \t value" form&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SequenceFileOutputFormat&lt;/td&gt;
&lt;td&gt;Writes binary files suitable for reading into subsequent MapReduce jobs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NullOutputFormat&lt;/td&gt;
&lt;td&gt;Disregards its inputs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;RecordWriters are used to write the individual records to the files as directed by the OutputFormat.&lt;/p&gt;
&lt;!--
Sources:
developpper.yahoo.com/hadoop/tutorial/module4.html
--&gt;</summary><category term="hadoop"></category></entry><entry><title>R: Experimentation of the Cental Limit Theorem</title><link href="http://stephanie-w.github.io/blog/experimentation-of-clt.html" rel="alternate"></link><updated>2015-08-10T16:19:08+02:00</updated><author><name>"Stephanie W"</name></author><id>tag:stephanie-w.github.io,2015-08-10:blog/experimentation-of-clt.html</id><summary type="html">&lt;hr /&gt;
&lt;p&gt;The CLT Theorem: &lt;br /&gt;
The distribution of sample statistics (e.g. mean) is approximatively normal, regardless of the underlying distribution, with mean = &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and variance = &lt;span class="math"&gt;\(\sigma^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To experiment this theory, we've built a matrix with 40 exponentials (we take lambda=0.2) x 1000 and compute the mean of each row, storing the result in a &lt;code&gt;means&lt;/code&gt; vector:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kp"&gt;set.seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;n &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;40&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;nosim &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1000&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;lambda &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;means &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;rexp&lt;span class="p"&gt;(&lt;/span&gt;nosim &lt;span class="o"&gt;*&lt;/span&gt; n&lt;span class="p"&gt;,&lt;/span&gt; lambda&lt;span class="p"&gt;),&lt;/span&gt; nosim&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;means&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;## [1] 4.602510 6.017790 5.463686 4.176755 7.144672 4.427567&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and plot an histogram of the &lt;code&gt;means&lt;/code&gt; vector and the density distribution:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;dat &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;nosim&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; means&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;dat&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; y&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_histogram&lt;span class="p"&gt;(&lt;/span&gt;colour &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; fill &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    geom_vline&lt;span class="p"&gt;(&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;xintercept &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;y&lt;span class="p"&gt;)),&lt;/span&gt; color &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;red&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; linetype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;dashed&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;        size &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Means&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Means Frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/means_histogram-1.png" title="plot of chunk means_histogram" alt="plot of chunk means_histogram" class="plot" /&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;dat&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; y&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_histogram&lt;span class="p"&gt;(&lt;/span&gt;binwidth &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; colour &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; fill &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    aes&lt;span class="p"&gt;(&lt;/span&gt;y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;..&lt;/span&gt;density..&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; stat_function&lt;span class="p"&gt;(&lt;/span&gt;fun &lt;span class="o"&gt;=&lt;/span&gt; dnorm&lt;span class="p"&gt;,&lt;/span&gt; args &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mean &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;lambda&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    sd &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;lambda&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="kp"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;n&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Means&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Dendity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Distribution&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    geom_density&lt;span class="p"&gt;(&lt;/span&gt;alpha &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; fill &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;#FF6666&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="rimage center"&gt;&lt;img src="figure/means_distribution-1.png" title="plot of chunk means_distribution" alt="plot of chunk means_distribution" class="plot" /&gt;&lt;/div&gt;

&lt;p&gt;To confirm this distribution fits the normal distribution, we've draw the hump of the density of a random variable normally distributed with a mean &lt;span class="math"&gt;\(1/\lambda\)&lt;/span&gt; and a standard deviation &lt;span class="math"&gt;\(\frac{1/\lambda}{\sqrt{n}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="R"></category><category term="stats"></category></entry><entry><title>R: Earthquakes from the past 30 days</title><link href="http://stephanie-w.github.io/blog/last_earthquakes.html" rel="alternate"></link><updated>2015-08-10T16:19:08+02:00</updated><author><name>Stephanie W</name></author><id>tag:stephanie-w.github.io,2015-08-10:blog/last_earthquakes.html</id><summary type="html">&lt;hr /&gt;


&lt;p&gt;Earthquakes of the last 30 months from &lt;a href="http://earthquake.usgs.gov/earthquakes/feed/v1.0/csv.php feed"&gt;the earthquake.usgs.gov feed&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;Below are the fields included in the spreadsheet output:
&lt;pre&gt;&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    time&lt;/span&gt;
&lt;span class="code-line"&gt;    latitude&lt;/span&gt;
&lt;span class="code-line"&gt;    longitude&lt;/span&gt;
&lt;span class="code-line"&gt;    depth&lt;/span&gt;
&lt;span class="code-line"&gt;    mag&lt;/span&gt;
&lt;span class="code-line"&gt;    magType&lt;/span&gt;
&lt;span class="code-line"&gt;    nst&lt;/span&gt;
&lt;span class="code-line"&gt;    gap&lt;/span&gt;
&lt;span class="code-line"&gt;    dmin&lt;/span&gt;
&lt;span class="code-line"&gt;    rms&lt;/span&gt;
&lt;span class="code-line"&gt;    net&lt;/span&gt;
&lt;span class="code-line"&gt;    id&lt;/span&gt;
&lt;span class="code-line"&gt;    updated&lt;/span&gt;
&lt;span class="code-line"&gt;    place&lt;/span&gt;
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;Plotting earthquakes frequency and location:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;reshape2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggmap&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;eq &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; as.is &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;eq&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;time&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;longitude&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;latitude&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;mag&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##                       time longitude latitude  mag&lt;/span&gt;
&lt;span class="code-line"&gt;## 1 2015-07-03T08:52:29.240Z -116.7768 33.27050 1.69&lt;/span&gt;
&lt;span class="code-line"&gt;## 2 2015-07-03T08:50:41.410Z -116.7822 33.27117 2.44&lt;/span&gt;
&lt;span class="code-line"&gt;## 3 2015-07-03T08:48:16.750Z -121.6347 37.24750 1.46&lt;/span&gt;
&lt;span class="code-line"&gt;## 4 2015-07-03T08:38:33.220Z  127.2178  1.20780 4.70&lt;/span&gt;
&lt;span class="code-line"&gt;## 5 2015-07-03T08:30:23.310Z -122.8367 38.80783 1.49&lt;/span&gt;
&lt;span class="code-line"&gt;## 6 2015-07-03T08:29:39.000Z -151.4705 62.43620 1.40&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;eq&lt;span class="o"&gt;$&lt;/span&gt;area &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;^[^,]+, &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; eq&lt;span class="o"&gt;$&lt;/span&gt;place&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;eq&lt;span class="o"&gt;$&lt;/span&gt;date &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;as.Date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;strtrim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;eq&lt;span class="o"&gt;$&lt;/span&gt;time&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; format &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%Y-%m-%dT%H:%M:%S&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;eqFreq1 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;eq&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="kp"&gt;date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; eq&lt;span class="o"&gt;$&lt;/span&gt;mag&lt;span class="p"&gt;,&lt;/span&gt; eq&lt;span class="o"&gt;$&lt;/span&gt;area&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;eqFreq2 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; melt&lt;span class="p"&gt;(&lt;/span&gt;eqFreq1&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;eqFreq2&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;M&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;area&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;freq&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;eqFreq2&lt;span class="p"&gt;,&lt;/span&gt; freq &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; M &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;##             date   M        area freq&lt;/span&gt;
&lt;span class="code-line"&gt;## 10831 2015-06-14 4.1 Afghanistan    3&lt;/span&gt;
&lt;span class="code-line"&gt;## 10838 2015-06-21 4.1 Afghanistan    1&lt;/span&gt;
&lt;span class="code-line"&gt;## 10844 2015-06-27 4.1 Afghanistan    1&lt;/span&gt;
&lt;span class="code-line"&gt;## 10870 2015-06-22 4.2 Afghanistan    1&lt;/span&gt;
&lt;span class="code-line"&gt;## 10887 2015-06-08 4.3 Afghanistan    1&lt;/span&gt;
&lt;span class="code-line"&gt;## 10894 2015-06-15 4.3 Afghanistan    2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;eqFreq2&lt;span class="o"&gt;$&lt;/span&gt;M &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;eqFreq2&lt;span class="o"&gt;$&lt;/span&gt;M&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;eqFreq2&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; weight &lt;span class="o"&gt;=&lt;/span&gt; freq&lt;span class="p"&gt;,&lt;/span&gt; fill &lt;span class="o"&gt;=&lt;/span&gt; M&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;(&lt;/span&gt;binwidth &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;24&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; labs&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    y &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Frequency&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; title &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Earthquakes Frequency from the past 30 days&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; theme&lt;span class="p"&gt;(&lt;/span&gt;axis.text.x &lt;span class="o"&gt;=&lt;/span&gt; element_text&lt;span class="p"&gt;(&lt;/span&gt;angle &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;90&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    hjust &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="" src="figure/earthquakes_frequency-1.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;world_map &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; map_data&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;world&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;p &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; coord_fixed&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; xlab&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; ylab&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;base_world &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; p &lt;span class="o"&gt;+&lt;/span&gt; geom_polygon&lt;span class="p"&gt;(&lt;/span&gt;data &lt;span class="o"&gt;=&lt;/span&gt; world_map&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; long&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; lat&lt;span class="p"&gt;,&lt;/span&gt; group &lt;span class="o"&gt;=&lt;/span&gt; group&lt;span class="p"&gt;),&lt;/span&gt; colour &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;light green&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    fill &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;light green&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;base_world &lt;span class="o"&gt;+&lt;/span&gt; geom_point&lt;span class="p"&gt;(&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; longitude&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; latitude&lt;span class="p"&gt;,&lt;/span&gt; size &lt;span class="o"&gt;=&lt;/span&gt; mag&lt;span class="p"&gt;),&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; eq&lt;span class="p"&gt;,&lt;/span&gt; colour &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Deep Pink&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    fill &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Pink&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; pch &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; alpha &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;I&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="" src="figure/earthquakes_worldmap-1.png" /&gt;&lt;/p&gt;</summary><category term="R"></category></entry></feed>